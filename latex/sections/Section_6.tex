\clearpage
\chapter{Discussion}
\label{sec:discussion}

In \cref{sec:data} to \cref{sec:workflows} we presented information processing and related tools in the context of complex electrophysiological experiments. The two described experiments demonstrate the evolution of approaches for data management in this context. The first example, described in \cref{sec:data}, is an electrophysiological experiment involving a macaque monkey trained for a reach to grasp task (Reach-to-Grasp experiment). The recording encompasses high resolution neuronal data as well as online and offline processed data versions together with task control and behavioural signals. The metadata in this project were collected retrospectively and in a variety of different formats involving different preprocessing steps performed by various scientists in using a variety of tools. We described the pipeline which was used to create a comprehensive metadata collection for two published datasets and discussed limitations of the chosen approach. Based on described metadata pipeline we identify essential requirements for the data and metadata handling in complex, collaborative projects.

In \cref{sec:metadata} we present \software{odMLtables}, an open-source tool aiding scientists in their daily routines to collect metadata in a standardized format. \software{odMLtables} facilitates the interaction with the hierarchical, \code{xml} based \software{odML} format by converting between \software{odML} and a tabular representation of the metadata, making the \software{odML} format accessible with widely used spreadsheet software. This is an important step for metadata collection, since a large fraction of metadata fail to be integrated into a standardized format.

A comprehensive metadata collection is essential for the interpretability of data. However, also data require a standardized representation for making them easily accessible to scientists. In \cref{sec:neo} we introduce the \software{Neo} project, which provides a standardize, generic data representation structure for electrophysiological data. We discuss the evolution of the \software{Neo} data representation and highlight the most important features, such as the support for numerous proprietary and open electrophysiological file formats and the generic structure with a flexible annotation mechanisms for custom desription of the data. For this purpose we demonstrate the usage of \software{Neo} in three code examples and list open source tools building on the \software{Neo} structure.

Finally we introduce the second electrophysiological experiment, the successor of the Reach-to-Grasp experiment, which is also recording neuronal signals from a behaving monkey, but in a more complex experimental design: In the Vision-for-Action experiment neuronal signals are recorded from two cortical areas at once using two parallel, synchronized recording setups. In addition the monkey is trained to track visual targets in a horizontal plane with a manually operated curser while his eye and hand movements are recorded in simultaneously. The organization of data and metadata in this experiment is designed for facilitated access and organization in later processing steps. We implemented a comprehensive metadata workflow integrating metadata in a modular, automatized fashion using the \code{snakemake} workflow management system and described the combination of data and metadata into user-friendly data packages. We evaluate the workflow based on the requirements identified in \cref{sec:data} and provide generalized guidelines for the design of future projects.


\section{Comparison of Reach-to-Grasp and Vision-for-Action data and metadata handling}
Since the implementation of the original metadata pipeline as published in the Reach-to-Grasp datasets \citep{Brochier_2018} software tools aiding data and metadata handling in neurosciences evolved (see e.g. \cref{sec:neo}). These changes in tool availability and conceptual differences in the planning and execution of the Vision-for-Action experiment led to different data and metadata approaches in the two projects. We discuss the differences with respect to specific aspects of the experiment in the following.

\subsection{Experimental design}
In the Reach-to-Grasp project systematic metadata collection started during the runtime of the experiment. This resulted in metadata being present in distributed files and various formats, aggravating the systematic collection. To quickly make the most essential metadata accessible with the data, the \code{ReachGraspIO} was implemented partially containing hard coded metadata. This decision complicated the systematic metadata aggregation in the long run by introducing circular dependencies in the metadata pipeline set up around the \code{IO}.
In the Vision-for-Action project we therefore tried to i) minimize the amount of metadata source files ii) provide them in a consistent, standardized format that is also human readable and user-friendly. The \code{csv} format fulfills these criteria, and together with additional structural restrictions, these tables can be easily converted to a hierarchical \software{odML} structure using \software{odMLtables} (\cref{sec:metadata}).
In addition internal changes in the design of the data recording were implemented: With the RIVER setup, special attention went into the integration of the three different types of recording systems. Instead of running the three systems for tracking neuronal, hand and eye data in parallel, these were integrated with the kinarm system acting as master system for signal integration and coordination and the two Neural Signal Processors serving as the output stream of the setup by not only writing neuronal, but also eye and hand signals via the two Cerebus systems to disc.
Another improvement implemented in the RIVER setup is the generic encoding of events, which is also used to systematically write parameters and additional metadata into the same files as the neuronal recording data. Storing the complete recording data and metadata in as few files as possible ensures to a high degree data consistency. The introduced generic encoding of events ameliorates the complex event interpretation as is was required in the Reach-to-Grasp experiment, where the interpretation of individual events depended on the history of previous events. With the introduced encoding events have a static interpretation independent of other events, they are more recording error robust as they always consist of a pair of events, forming an information block and they are can be flexibly used for different modes (e.g. task types) of the recording as each task has a unique mapping from these generic to task specific events.

\subsection{Build philosophy}
\todo{R2G: separate structure and content, V4A combine}

\subsection{Pipeline and workflow approach}
\subsection{}

\section{Next steps} \todo{what is building on top of this? Neo and other tools, what options does this offer, 2nd data publcation?}

\todo{mention improved approaches on the experimental side, better metadata tracking, less files, systematic, generic approach...}

\begin{itemize}
 \item differences in the approach R2G vs V4A -> advantages of only nix output, more general concepts, guidelines?
 \item the future of Neo
 \item have the published datasets been reused yet? was it worth publishing?
 \item what to consider BEFORE starting an experiment
 \item generalize concepts to other modalities. simulations? eeg data? nfdi?
 \item embedding of snakemake in gin, continuous integration \& deployment concepts
 \item can the data quality be perfect already at recording?
 \item building on top, elephant and other analysis tools (\cref{Unakafova_2019})
\end{itemize}



% ...
% \subsection{Exemplary Figure}
% \label{subsec:Section_Name/fig}
% ...
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=.5\linewidth]{./Figures/UoC_Logo.png}
%     \caption{Exemplary Figure}
%     \label{fig:UoC}
% \end{figure}
% 
% 
% \subsection{Exemplary Figure Referencing}
% \label{subsec:Section_Name/fig_rfs}
% 
% See Figure \cref{fig:UoC} for details. Additional information can be
% found in the footnote \footnote{Image taken from \url{https://en.wikipedia.org/wiki/File:Siegel_Uni-Koeln_(Grau).svg}.}.
