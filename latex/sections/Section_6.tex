\clearpage
\chapter{Discussion}
\label{sec:discussion}

In \cref{sec:data} to \cref{sec:workflows} we presented information processing and related tools in the context of complex electrophysiological experiments. The two described experiments demonstrate the evolution of approaches for data management in this context. The first example, described in \cref{sec:data}, is an electrophysiological experiment involving a macaque monkey trained for a reach to grasp task (Reach-to-Grasp experiment). The recording encompasses high resolution neuronal data as well as online and offline processed data versions together with task control and behavioural signals. The metadata in this project were collected retrospectively and in a variety of different formats involving different preprocessing steps performed by various scientists in using a variety of tools. We described the pipeline which was used to create a comprehensive metadata collection for two published datasets and discussed limitations of the chosen approach. Based on described metadata pipeline we identify essential requirements for the data and metadata handling in complex, collaborative projects.

In \cref{sec:metadata} we present \software{odMLtables}, an open-source tool aiding scientists in their daily routines to collect metadata in a standardized format. \software{odMLtables} facilitates the interaction with the hierarchical, \code{xml} based \software{odML} format by converting between \software{odML} and a tabular representation of the metadata, making the \software{odML} format accessible with widely used spreadsheet software. This is an important step for metadata collection, since a large fraction of metadata fail to be integrated into a standardized format.

A comprehensive metadata collection is essential for the interpretability of data. However, also data require a standardized representation for making them easily accessible to scientists. In \cref{sec:neo} we introduce the \software{Neo} project, which provides a standardize, generic data representation structure for electrophysiological data. We discuss the evolution of the \software{Neo} data representation and highlight the most important features, such as the support for numerous proprietary and open electrophysiological file formats and the generic structure with a flexible annotation mechanisms for custom desription of the data. For this purpose we demonstrate the usage of \software{Neo} in three code examples and list open source tools building on the \software{Neo} structure.

Finally we introduce the second electrophysiological experiment, the successor of the Reach-to-Grasp experiment, which is also recording neuronal signals from a behaving monkey, but in a more complex experimental design: In the Vision-for-Action experiment neuronal signals are recorded from two cortical areas at once using two parallel, synchronized recording setups. In addition the monkey is trained to track visual targets in a horizontal plane with a manually operated curser while his eye and hand movements are recorded in simultaneously. The organization of data and metadata in this experiment is designed for facilitated access and organization in later processing steps. We implemented a comprehensive metadata workflow integrating metadata in a modular, automatized fashion using the \code{snakemake} workflow management system and described the combination of data and metadata into user-friendly data packages. We evaluate the workflow based on the requirements identified in \cref{sec:data} and provide generalized guidelines for the design of future projects.


\section{Comparison of Reach-to-Grasp and Vision-for-Action data and metadata handling}
Since the implementation of the original metadata pipeline as published in the Reach-to-Grasp datasets \citep{Brochier_2018} software tools aiding data and metadata handling in neurosciences evolved (see e.g. \cref{sec:neo}). These changes in tool availability and conceptual differences in the planning and execution of the Vision-for-Action experiment led to different data and metadata approaches in the two projects. We discuss the differences with respect to specific aspects of the experiment in the following.

\subsection{Experimental design}
In the Reach-to-Grasp project systematic metadata collection started during the runtime of the experiment. This resulted in metadata being present in distributed files and various formats, aggravating the systematic collection. To quickly make the most essential metadata accessible with the data, the \code{ReachGraspIO} was implemented partially containing hard coded metadata. This decision complicated the systematic metadata aggregation in the long run by introducing circular dependencies in the metadata pipeline set up around the \code{IO}.
In the Vision-for-Action project we therefore tried to i) minimize the amount of metadata source files ii) provide them in a consistent, standardized format that is also human readable and user-friendly. The \code{csv} format fulfills these criteria, and together with additional structural restrictions, these tables can be easily converted to a hierarchical \software{odML} structure using \software{odMLtables} (\cref{sec:metadata}).
In addition internal changes in the design of the data recording were implemented: With the RIVER setup, special attention went into the integration of the three different types of recording systems. Instead of running the three systems for tracking neuronal, hand and eye data in parallel, these were integrated with the kinarm system acting as master system for signal integration and coordination and the two Neural Signal Processors serving as the output stream of the setup by not only writing neuronal, but also eye and hand signals via the two Cerebus systems to disc.
Another improvement implemented in the RIVER setup is the generic encoding of events, which is also used to systematically write parameters and additional metadata into the same files as the neuronal recording data. Storing the complete recording data and metadata in as few files as possible ensures to a high degree data consistency. The introduced generic encoding of events ameliorates the complex event interpretation as is was required in the Reach-to-Grasp experiment, where the interpretation of individual events depended on the history of previous events. With the introduced encoding events have a static interpretation independent of other events, they are more recording error robust as they always consist of a pair of events, forming an information block and they are can be flexibly used for different modes (e.g. task types) of the recording as each task has a unique mapping from these generic to task specific events.

\subsection{Metadata aggregation concept}
\label{sec:disscussion_metadata_concept}
The concept for compiling a metadata collection differs between the Reach-to-Grasp and the Vision-for-Action experiment (\cref{fig:discussion_comparison_r2g_v4a}). In the first one, the metadata structure is defined via a set of templates, which provide an \software{odML} structure containing default values. These templated are put together to build a complete template metadata structure. However for generating a suitable template structure information from the metadata sources is already required introducing additional interdependencies in the process and complicating the metadata aggregation (\cref{fig:discussion_comparison_r2g_v4a}, red arrow). In the next step the default values will be replaced with the actual metadata entries extracted from the various source files, which again requires knowledge about the odML structure in a semi hardcoded fashion. Additionally, during the aggregation process the metadata pipeline explicitely attempts to resolve a number of interdependencies between the different metadata sources. This example demonstrats that the intended separation between the structure and content of the metadata collection is not feasible due to dependencies between the two, introducing additional overhead and exception handling in the metadata aggregation procedure.
In the Vision-for-Action project the metadata aggregation is implemented in a different way: The metadata structure is generated by the the same function, which extracts the metadata from a source file. This way the metadata content and structure for a specific part of information are handled at the same location in the code and is not distributed. This simplifies the metadata aggregation process and permits to split the process into multiple, independent processes (\cref{fig:discussion_comparison_r2g_v4a}).

\begin{figure}
 \centering
 \includesvg[width=\textwidth, pretex=\relscale{0.8}]{figures/discussion_odml_build_comparison.svg}
 \caption[Metadata aggregation comparison Reach-to-Grasp and Vision-for-Action]{Metadata aggregation comparison Reach-to-Grasp and Vision-for-Action. In the Reach-to-Grasp project, the metadata structure generation is strictly separated from the metadata content (left), whereas in the Vision-for-Action project the structure is generated  piecewise during the metadata is aggregation.}
 \label{fig:discussion_comparison_r2g_v4a}
\end{figure}

\subsection{Software evolution}
% odML
The Reach-to-Grasp metadata pipeline was implemented using \software{odML} version 1.3, in which a \software{odML} \code{Properties} can only be generated when containing at least one \code{Value}. This constraint makes the \software{odML} structure as intermediately generated by the Reach-to-Grasp workflow unnessarily complicated by enforcing the usage of default values for all potential \code{Value} entries. With the release of \software{odML} version 1.4 this constraint was lifted, such that an \software{odML} structure can be created without any \code{Value} entries. Updating the Reach-to-Grasp metadata aggregation pipeline to \software{odML} version 1.4 would therefore slightly simplify pipeline. However, this does not resolve conceptual issues related to the general metadata aggregation concept.

%Nix
Additionally, when the Reach-to-Grasp metadata pipline was implemented \software{Neo} did not yet support the \software{Nix} format. For this reason, the metadata aggregation pipeline was used to generate a metadata collection in the \software{odML} format, but did not combine data and metadata in a single file. For this purpose the \code{ReachGraspIO} was implemented to provide a comparable functionality at runtime. However, this introduced additional interdependencies within the project (\cref{sec:disscussion_metadata_concept}) and attenuated the user-friendlyness by requiring the usage of custom code.

\todo{any more updates worth mentioning?}

\subsection{Usability}
The Reach-to-Grasp pipeline generates a single \software{odML} file per recording session. Therefore accessing the data as well as the metadata requires the user to have  specific, compatible versions of data and metadata files and software packages set up. This includes the metadata in \software{odML} format, the data distributed across one \code{nev}, \code{ns2} and \code{ns6} file for each recording session. In addition the \software{Neo} and \software{odML} Python packages as well as the custom \code{ReachGraspIO} is required for accessing all information contained in the data and metadata files. This, however, does only provide basic annotation of the data with content from the metadata collection and does not provide direct linking between data and metadata structures. In case the users require additional metadata beyond the annotations, they need to find and extract this information manually from the metadata collection.

Applying the same strategy in the Vision-for-Action project would have resulted a number of metadata source files and in addition two sets of neuronal data files, as the setup contains two NSPs. Therefore, here the data and metadata workflow generates a \software{Nix} file combining data and metadata in a single framework, if which the data and basic metadata are accessible requiring only the Python \software{Neo} package. For accessing additional metadata any commonly available \code{hdf5} viewer can be used. A project in development for visualization of \software{Nix} files taking into account basic metadata is \software{NixView}\footnote{NixView, \url{https://github.com/bendalab/nixview}}. Combining data and metadata in a single file guarantees the correspondance between the two, whereas in the Reach-to-Grasp project this needs to asserted manually.

\subsection{Pipeline and workflow approach}
Within the Reach-to-Grasp project a single Python script is coordinating the generation of the \software{odML} structure and enrichment with metadata. This results in convoluted code trying to separate the \software{odML} structure and metadata sources with moderate success. In the Vision-for-Action project this separation is not intended, but in constrast actively avoided resulting in a much more flexible, reusable and scalable workflow consisting of modular steps interacting only via their in- and output files. In addition, the workflow is easier to understand as the dependencies can be automatically visualized and the workflow can inherently be executed piecewise, which aids troubleshooting and exploration. In addition the workflow steps can be separated into generic and experiment specific components providing a basis for the exchange and sharing of metadata workflow approaches across projects and laboratories. This automatically makes data and metadata handling more comparable and provides therefore a foundation for exchange and publication of scientific data. For this reason we abstracted a set of general guidelines for the handling of data and metadata from our experiences, which are described in \cref{sec:guidelines}.

\section{Outlook}

\subsection{The future of \software{odMLtables}}
\software{odMLtables} emerged from a collection of \software{odML} utility functions accumulating in the context of the Reach-to-Grasp project. Currently it is a standalone Python package with key dependencies on \software{odML} and \software{PyQt5} for the graphical user interface (gui) providing non-programming access to the core features of \software{odMLtables}. For historic reasons, \software{odMLtables} internally uses a custom, dictionary based representation of the \software{odML} structure. Replacing this with a native \software{odML} Python object would ensure consistency during the metadata manipulation using \software{odMLtables}.

In addition to \software{odMLtables} also a native \software{odML} editor, \software{odML-UI}, exists, which only operates on the hierarchical \software{odML} representation. Currently the four main features of the \software{odMLtables} gui can be accessed via \software{odML-UI} if \software{odMLtables} is installed. However, in the long run it would be most user friendly to integrate the two tools into a single one to reduce the dependencies on the user side and provide a more concise set of tools for metadata handling. With an enhanced \software{odMLtables} version using a Python \software{odML} representation internally, integration of the two tools should be straightforward.

\subsection{The future of \software{Neo}}
We descibed the evolution of the \software{Neo} package from the original publication \cite{Garcia_2014} to the current version $0.7.2$ as well as potential enhancements in future version in \cref{sec:neo}. It has been seen, that the basic concepts for capturing data within \software{Neo} objects is rather stable and also the \software{Neo} container objects for handling temporal relations between these data object structure (\code{Segments}) did not change a lot in the last releases. In contrast to that, the container objects for capturing channel and rather generic relations was updated frequently. In \software{Neo} version $0.3$ this encompasses \code{RecordingChannel}s and \code{RecordingChannelGroup}s and in \software{Neo} version 0.7 this comprises \code{ChannelIndex}es. We suggest to split the different functionalities \code{ChannelIndex}es cover. A first step of this is already implemented in the form of array annotations. The in the next steps we suggest to introduce \code{Group} and \code{View} objects. However this suggestion is still under debate and might be adjusted in the future. 

With the release of \software{Neo} version $0.6$ a standardized API for readers was introduced. This harmonized the various different implementation approaches collected in the \software{Neo} framework and at the same time improved the performance of the readers. However, this only affects the reading aspect of \code{Neo}. On the writing side, there is no standardization of code, since the writing to various different formats requires more diverse code organization than funneling different file formats into a single representation. Additionally, the \code{IO}s capable of writing are limited to currently eight, meaning a the effort of finding a code structure suited for general writing would only standardize eight implementations. However, two usefull extensions on the writing side would be i) a validator, checking the integrity before writing the \software{Neo} structure to disc and forming a standard of valid and writable \software{Neo} structures and ii) unittests for ensuring the compatibility between writable and readable \software{Neo} structures (see \cref{fig:disc_neo_plans}).

\subsection{The future of workflow management}
With the pilot study investigating the integration of \software{snakemake} workflows in the the \software{Gin} web service\footnote{gin-proc, \url{https://github.com/G-Node/gin-proc}} the development takes direction towards a fully automated data and metadata workflow, where the creation of new recording data files tiggers the workflow annotating, preprocessing and preparing these data in a version controlled manner for the scientific usage. This continuous integration and deployment of the data to a central location would be the ideal prerequisite for a scientific collaborations.

\begin{figure}
 \includesvg[width=\textwidth]{figures/discussion_neo.svg}
 \caption[\software{Neo} IOs and future plans]{\software{Neo} IOs and future plans. \software{Neo} supports reading of multiple file formats. A large fraction of these formats is read via standardized implementations of readers whereas other rely on format-specific, custom implementations. In addition, \software{Neo} can write to a number of formats with custom writers. We suggest to extend the current implementation with a \code{validation} mechanism as well as a systematic \code{unittest} approach for formats that are read- and writable which ensures coherent reading and writing functionality (dashed panels).}
 \label{fig:disc_neo_plans}
\end{figure}

\subsection{Data analysis}
For analysis of electrophysiological data there are a number of tools available with differerent analysis foci (e.g. see \citet{Unakafova_2019}). Since the data and metadata workflow presented in \ref{sec:workflows} creates a comprehensive data representation in the \code{hdf5} format, in principle any of these toolboxes can be used for analysis as long as \code{hdf5} reading capability is available in the corresponding programming language. However, analysing the data using a \software{Neo} based approach provides a direct and simple access to the data. This leaves mainly thee tools for data analysis based on \software{Neo}: \software{Tridesclous} for spike sorting, \software{Open Electrophy} for viewing and explorative analysis and \software{Elephant} for comprehensive data analysis. Of course the data can also be extracted from the \software{Neo} structure and used in any other Python based analysis tool, however this forfeits the inherent data consistency and metadata annotations. Therefore \software{Elephant} is the tool of choice here. It offers a wide range of basic and a number of advanced methods for analysis of spiking and continuous neural signal activity. As \software{Elephant} being a community-driven open-source toolkit also extensions are highly welcome.
\todo{go more into detail about elephant?}

\subsection{Published datasets}
The two electrophysiological datasets described in \citep{Brochier_2018} and published in April 2018 have not been reused in an independent study. This might be due to the fact, that even though the dataset is very rich, is is also limited to a single cortical area and a monkey performing a very specific task. Therefore the dataset might be of scientific interest for two types of scientists: i) researchers investigating very similar questions as we do, who typically already have collaborations or perform their own experiments or ii) researchers looking for a generic example datasets, e.g. to develop new workflows or test new processing and analysis methods. For these, this dataset might not be visible enough or the extensive description dissuasive, as typically much less metadata is required for these purposes. However, the publication of the dataset has paid off by having a publicly available example of the type of data we deal with. This can be seen for example in the number of citations\footnote{number of citations of \citep{Brochier_2018} on 23rd of August 2019 (1 year and 4.5 months after publication): 6} demonstrating the importance of doing the effort to publish data. Additionally these datasets have been frequently used for teaching purposes, e.g. in tutorial jupyter notebooks introducing \software{snakemake} workflows, \software{Neo} and or \software{Elephant}, e.g. at the University of Toronto\footnote{\url{https://github.com/UofTCoders/Events/issues/239} and \url{https://github.com/UofTCoders/studyGroup/tree/gh-pages/lessons/python/snakemake_elephant_demo}}.

\subsection{Lessons to learn}
As already hinted at in the future challenges for the Vision-for-Action workflow (\cref{sec:workflow_discussion}) and the guidelines formulated in \cref{sec:guidelines}, we applied a couple of concepts from the commercial \todo{professional????} software development community in the in the workflow implementation. Some concepts which can be for example adapted also for scientific software e.g. from the agile software development are pair programming, continous integration, short feedback loops and continous deployment. However, recognizing and implementing these concepts requires practice, meaning that the potential to learn from the software development community is great, but it takes time.

\subsection{Concept extension}
On the software side, the described workflow is based in specific research area of neurophysiology by dealing with electrophysiological data from an monkey experiment. However, in principle the tools presented are or will be capable of dealing with different modalities. For example the description of an electroencephalographic (EEG), functional magnetic resonance imaging (fMRI) dataset or a spiking network simulation (e.g. using Nest\footnote{Nest, \url{https://www.nest-simulator.org/}, RRID:SCR\_002963, doi:10.5281/zenodo.2605421}) should be possible using similar means as presented here. This would permit to easily apply the same analysis methods on the datasets and would therefore form a bridge between the different areas of neuroscience.
On an larger scale the development of concepts and tools for data and metadata management across scientific disciplines is an area of active development \todo{cite NFDI here?}. Here our efforts to provide a generic toolset located within the field of neuroscience provides a foundation for the integration with other fields of science.

\subsection{Next steps}
The implementation of the data and metadata pipeline is a natural precursor to publishing the datasets, such that the research community can benefit from the invested effort. As the workflow is not completely implemented and running in a fully automated fashion yet, this will still take some time. The estimated completion date is early 2020.

\subsection{Visions}
A large part of the efforts presented in this manuscript arose from the fact that data generated by commercial recording systems were not complete and free of unintended signals (artifacts). This lead to to two types of development: the aggregation of as much information as possible concerning the recording circumstances and the development of extensive preprocessing steps including artifact detecton. The question is: is this really necessary and will it always be like this?

For the first aspect this is diligent work requiring first of all commercial recording setup producers to take this aspect into consideration and extend and adjust their system according to the needs of scientist to comprehensively track the data generation. For custom build setups or integrated systems as in the case of Vision-for-Action will still be in the scope of duties of the scientist to be aware of this issue and tackle it early in the experiment development process.

For the second aspect of artifacts in recording data this is an issue typically improving with technical development, e.g. better insulation of cables or less error-prone communication protocols. However, no experimental setup will ever be completely free of artifacts and also the change to the latest technology will never guarantee unintended side effects in the data. Therefore carefull quality checks of recording data will always be necessary, only the amount of contaminated data might reduce with technical progress.

For these reasons workflows like the one presented in \cref{sec:workflows} deal with an essential aspect of scientific research and are the key to well-founded scientific findings.
