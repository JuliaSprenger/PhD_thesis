\clearpage
\chapter{Discussion}
\label{sec:discussion}

In \cref{sec:data} to \cref{sec:workflows} we presented information processing and related tools in the context of complex electrophysiological experiments. The two described experiments demonstrate the evolution of approaches for data management in this context. The first example, described in \cref{sec:data}, is an electrophysiological experiment involving a macaque monkey trained for a reach to grasp task (Reach-to-Grasp experiment). The recording encompasses high resolution neuronal data as well as online and offline processed data versions together with task control and behavioural signals. The metadata in this project were collected retrospectively and in a variety of different formats involving different preprocessing steps performed by various scientists in using a variety of tools. We described the pipeline which was used to create a comprehensive metadata collection for two published datasets and discussed limitations of the chosen approach. Based on described metadata pipeline we identify essential requirements for the data and metadata handling in complex, collaborative projects.

In \cref{sec:metadata} we present \software{odMLtables}, an open-source tool aiding scientists in their daily routines to collect metadata in a standardized format. \software{odMLtables} facilitates the interaction with the hierarchical, \code{xml} based \software{odML} format by converting between \software{odML} and a tabular representation of the metadata, making the \software{odML} format accessible with widely used spreadsheet software. This is an important step for metadata collection, since a large fraction of metadata fail to be integrated into a standardized format.

A comprehensive metadata collection is essential for the interpretability of data. However, also data require a standardized representation for making them easily accessible to scientists. In \cref{sec:neo} we introduce the \software{Neo} project, which provides a standardize, generic data representation structure for electrophysiological data. We discuss the evolution of the \software{Neo} data representation and highlight the most important features, such as the support for numerous proprietary and open electrophysiological file formats and the generic structure with a flexible annotation mechanisms for custom desription of the data. For this purpose we demonstrate the usage of \software{Neo} in three code examples and list open source tools building on the \software{Neo} structure.

Finally we introduce the second electrophysiological experiment, the successor of the Reach-to-Grasp experiment, which is also recording neuronal signals from a behaving monkey, but in a more complex experimental design: In the Vision-for-Action experiment neuronal signals are recorded from two cortical areas at once using two parallel, synchronized recording setups. In addition the monkey is trained to track visual targets in a horizontal plane with a manually operated curser while his eye and hand movements are recorded in simultaneously. The organization of data and metadata in this experiment is designed for facilitated access and organization in later processing steps. We implemented a comprehensive metadata workflow integrating metadata in a modular, automatized fashion using the \code{snakemake} workflow management system and described the combination of data and metadata into user-friendly data packages. We evaluate the workflow based on the requirements identified in \cref{sec:data} and provide generalized guidelines for the design of future projects.


\section{Comparison of Reach-to-Grasp and Vision-for-Action data and metadata handling}
Since the implementation of the original metadata pipeline as published in the Reach-to-Grasp datasets \citep{Brochier_2018} software tools aiding data and metadata handling in neurosciences evolved (see e.g. \cref{sec:neo}). These changes in tool availability and conceptual differences in the planning and execution of the Vision-for-Action experiment led to different data and metadata approaches in the two projects. We discuss the differences with respect to specific aspects of the experiment in the following.

\subsection{Experimental design}
In the Reach-to-Grasp project systematic metadata collection started during the runtime of the experiment. This resulted in metadata being present in distributed files and various formats, aggravating the systematic collection. To quickly make the most essential metadata accessible with the data, the \code{ReachGraspIO} was implemented partially containing hard coded metadata. This decision complicated the systematic metadata aggregation in the long run by introducing circular dependencies in the metadata pipeline set up around the \code{IO}.
In the Vision-for-Action project we therefore tried to i) minimize the amount of metadata source files ii) provide them in a consistent, standardized format that is also human readable and user-friendly. The \code{csv} format fulfills these criteria, and together with additional structural restrictions, these tables can be easily converted to a hierarchical \software{odML} structure using \software{odMLtables} (\cref{sec:metadata}).
In addition internal changes in the design of the data recording were implemented: With the RIVER setup, special attention went into the integration of the three different types of recording systems. Instead of running the three systems for tracking neuronal, hand and eye data in parallel, these were integrated with the kinarm system acting as master system for signal integration and coordination and the two Neural Signal Processors serving as the output stream of the setup by not only writing neuronal, but also eye and hand signals via the two Cerebus systems to disc.
Another improvement implemented in the RIVER setup is the generic encoding of events, which is also used to systematically write parameters and additional metadata into the same files as the neuronal recording data. Storing the complete recording data and metadata in as few files as possible ensures to a high degree data consistency. The introduced generic encoding of events ameliorates the complex event interpretation as is was required in the Reach-to-Grasp experiment, where the interpretation of individual events depended on the history of previous events. With the introduced encoding events have a static interpretation independent of other events, they are more recording error robust as they always consist of a pair of events, forming an information block and they are can be flexibly used for different modes (e.g. task types) of the recording as each task has a unique mapping from these generic to task specific events.

\subsection{Metadata aggregation concept}
\label{sec:disscussion_metadata_concept}
The concept for compiling a metadata collection differs between the Reach-to-Grasp and the Vision-for-Action experiment (\cref{fig:discussion_comparison_r2g_v4a}). In the first one, the metadata structure is defined via a set of templates, which provide an \software{odML} structure containing default values. These templated are put together to build a complete template metadata structure. However for generating a suitable template structure information from the metadata sources is already required introducing additional interdependencies in the process and complicating the metadata aggregation (\cref{fig:discussion_comparison_r2g_v4a}, red arrow). In the next step the default values will be replaced with the actual metadata entries extracted from the various source files, which again requires knowledge about the odML structure in a semi hardcoded fashion. Additionally, during the aggregation process the metadata pipeline explicitely attempts to resolve a number of interdependencies between the different metadata sources. This example demonstrats that the intended separation between the structure and content of the metadata collection is not feasible due to dependencies between the two, introducing additional overhead and exception handling in the metadata aggregation procedure.
In the Vision-for-Action project the metadata aggregation is implemented in a different way: The metadata structure is generated by the the same function, which extracts the metadata from a source file. This way the metadata content and structure for a specific part of information are handled at the same location in the code and is not distributed. This simplifies the metadata aggregation process and permits to split the process into multiple, independent processes (\cref{fig:discussion_comparison_r2g_v4a}).

\begin{figure}
 \centering
 \includesvg[width=\textwidth, pretex=\relscale{0.8}]{figures/discussion_odml_build_comparison.svg}
 \caption[Metadata aggregation comparison Reach-to-Grasp and Vision-for-Action]{Metadata aggregation comparison Reach-to-Grasp and Vision-for-Action. In the Reach-to-Grasp project, the metadata structure generation is strictly separated from the metadata content (left), whereas in the Vision-for-Action project the structure is generated  piecewise during the metadata is aggregation.}
 \label{fig:discussion_comparison_r2g_v4a}
\end{figure}

\subsection{Software evolution}
% odML
The Reach-to-Grasp metadata pipeline was implemented using \software{odML} version 1.3, in which a \software{odML} \code{Properties} can only be generated when containing at least one \code{Value}. This constraint makes the \software{odML} structure as intermediately generated by the Reach-to-Grasp workflow unnessarily complicated by enforcing the usage of default values for all potential \code{Value} entries. With the release of \software{odML} version 1.4 this constraint was lifted, such that an \software{odML} structure can be created without any \code{Value} entries. Updating the Reach-to-Grasp metadata aggregation pipeline to \software{odML} version 1.4 would therefore slightly simplify pipeline. However, this does not resolve conceptual issues related to the general metadata aggregation concept.

%Nix
Additionally, when the Reach-to-Grasp metadata pipline was implemented \software{Neo} did not yet support the \software{Nix} format. For this reason, the metadata aggregation pipeline was used to generate a metadata collection in the \software{odML} format, but did not combine data and metadata in a single file. For this purpose the \code{ReachGraspIO} was implemented to provide a comparable functionality at runtime. However, this introduced additional interdependencies within the project (\ref{sec:disscussion_metadata_concept}) and attenuated the user-friendlyness by requiring the usage of custom code.

\todo{any more updates worth mentioning?}

\subsection{Usability}
The Reach-to-Grasp pipeline generates a single \software{odML} file per recording session. Therefore accessing the data as well as the metadata requires the user to have  specific, compatible versions of data and metadata files and software packages set up. This includes the metadata in \software{odML} format, the data distributed across one \code{nev}, \code{ns2} and \code{ns6} file for each recording session. In addition the \software{Neo} and \software{odML} Python packages as well as the custom \code{ReachGraspIO} is required for accessing all information contained in the data and metadata files. This, however, does only provide basic annotation of the data with content from the metadata collection and does not provide direct linking between data and metadata structures. In case the users require additional metadata beyond the annotations, they need to find and extract this information manually from the metadata collection.

The data and metadata workflow in the Vision-for-Action project generates a \software{Nix} file combining data and metadata in a single framework, if which the data and basic metadata are accessible requiring only the Python \software{Neo} package. For accessing additional metadata any commonly available \code{hdf5} viewer can be used. Combining data and metadata in a single file guarantees the correspondance between the two, whereas in the Reach-to-Grasp project this needs to asserted manually.

\subsection{Pipeline and workflow approach}
Within the Reach-to-Grasp project a single Python script is coordinating the generation of the \software{odML} structure and enrichment with metadata. This results in convoluted code trying to separate the \software{odML} structure and metadata sources with moderate success. In the Vision-for-Action project this separation is not intended, but in constrast actively avoided resulting in a much more flexible, reusable and scalable workflow consisting of modular steps interacting only via their in- and output files. In addition, the workflow is easier to understand as the dependencies can be automatically visualized and the workflow can inherently be executed piecewise, which aids troubleshooting and exploration. In addition the workflow steps can be separated into generic and experiment specific components providing a basis for the exchange and sharing of metadata workflow approaches across projects and laboratories. This automatically makes data and metadata handling more comparable and provides therefore a foundation for exchange and publication of scientific data. For this reason we abstracted a set of general guidelines for the handling of data and metadata from our experiences, which are described in \cref{sec:guidelines}.

\section{Outlook}

\subsection{The future of \software{odMLtables}}
\software{odMLtables} emerged from a collection of \software{odML} utility functions accumulating in the context of the Reach-to-Grasp project. Currently it is a standalone Python package with key dependencies on \software{odML} and \software{PyQt5} for the graphical user interface (gui) providing non-programming access to the core features of \software{odMLtables}. For historic reasons, \software{odMLtables} internally uses a custom, dictionary based representation of the \software{odML} structure. Replacing this with a native \software{odML} Python object would ensure consistency during the metadata manipulation using \software{odMLtables}.

In addition to \software{odMLtables} also a native \software{odML} editor, \software{odML-UI}, exists, which only operates on the hierarchical \software{odML} representation. Currently the four main features of the \software{odMLtables} gui can be accessed via \software{odML-UI} if \software{odMLtables} is installed. However, in the long run it would be most user friendly to integrate the two tools into a single one to reduce the dependencies on the user side and provide a more concise set of tools for metadata handling. With an enhanced \software{odMLtables} version using a Python \software{odML} representation internally, integration of the two tools should be straightforward.

\subsection{The future of \software{Neo}}

\section{Next steps} \todo{what is building on top of this? Neo and other tools, what options does this offer, 2nd data publcation?}

\begin{itemize}
 \item the future of Neo
 \item have the published datasets been reused yet? was it worth publishing?
 \item what to consider BEFORE starting an experiment
 \item generalize concepts to other modalities. simulations? eeg data? nfdi?
 \item embedding of snakemake in gin, continuous integration \& deployment concepts
 \item can the data quality be perfect already at recording?
 \item building on top, elephant and other analysis tools (\cref{Unakafova_2019})
\end{itemize}



% ...
% \subsection{Exemplary Figure}
% \label{subsec:Section_Name/fig}
% ...
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=.5\linewidth]{./Figures/UoC_Logo.png}
%     \caption{Exemplary Figure}
%     \label{fig:UoC}
% \end{figure}
% 
% 
% \subsection{Exemplary Figure Referencing}
% \label{subsec:Section_Name/fig_rfs}
% 
% See Figure \cref{fig:UoC} for details. Additional information can be
% found in the footnote \footnote{Image taken from \url{https://en.wikipedia.org/wiki/File:Siegel_Uni-Koeln_(Grau).svg}.}.
