\clearpage
\chapter[Sharing data]{Sharing data\\- Publication of two complex electrophysiological datasets}
\label{sec:data}

Scientific progress is the result of scientific findings that build on each other. To validate such findings, typically hypothesis are proposed and tested against experimental data using statistical methods. The resulting finding and interpretation is communicated to other scientists via the publication of a manuscript. In recent years, however, the practice of publishing papers has been criticized for a lack of robustness. Attempts in a number of scientific fields including life sciences, among others, to reproduce published scientific findings failed to support the same conclusions \citep{Baker_2016, Fidler_2017, Pashler_2012, Ioannidis_2005, Goodman_2007, Ioannidis_2007, OpenScienceCollaboration_2015}. To qualitatively distinguish between different levels of reproducibility, a collection of terms has been applied: reproducibility, replicability, repeatability \citep{Plesser_2018, Drummond_2009}. However the specific interpretation of each of these terms highly depends on the scientific field they are applied in. Repeatability, for example, can be defined as the re-performance of the same experimental study using identical components. However, for computer sciences repeating an experiment might be the re-running of the same software simulation on the same machine using the same software packages. In consequence, the feasibility of repeating a study highly depends on the field. For example repeating an study by running the same code on the identical machine might be a realistic project, whereas running the identical experiment in psychology is not \citep{Anderson_2016}. A widely accepted version of reproducibility terminology by \citet{Goodman_2007} is therefore omitting the terms 'replicability' and 'repeatability' for simplification and defines instead three different types of reproducibility \citep[from][]{Plesser_2018}:

\begin{minipage}{\textwidth}
\begin{description}
 \item[Methods reproducibility] \hfill \\ \textit{'provide sufficient detail about procedures and data so that the same procedures could be exactly repeated.'}
\item[Results reproducibility] \hfill \\ \textit{'obtain the same results from an independent study with procedures as closely matched to the original study as possible.'}
\item[Inferential reproducibility] \hfill \\ \textit{'draw the same conclusions from either an independent replication of a study or a reanalysis of the original study.'}\\
\end{description}
\end{minipage}

The definition of 'methods reproducibility' highlights a central aspect of scientific publications: the underlying data. Reproducing findings of publications is difficult for older publications \citep{Vines_2013,Rostami_2017}, which to a large part can be accounted for by the decreasing ability to retrieve of the original datasets. The obligation to provide research data to other scientists is a practice promoted by increasingly many funding organizations (e.g. NIH since 2003\footnote{\url{https://grants.nih.gov/grants/policy/data_sharing/}}, EU Horizon 2020 Open Research Data Pilot\footnote{\url{https://ec.europa.eu/research/participants/docs/h2020-funding-guide/cross-cutting-issues/open-access-data-management/data-management_en.htm}} since 2014) for publications in a number of journals (e.g. Springer Nature\footnote{\url{https://www.springernature.com/gp/authors/research-data-policy/data-availability-statements/12330880}}), however the readiness to comply is rather low (1/10 publications provides research data on request \citep{Savage_2009}. To address the problem of methods reproducibility for original research articles, a number of new journals were put into place, which invite to publish replications of the original articles in computational science \footnote{ReScience, \url{http://rescience.github.io/}}, economics\footnote{\url{http://www.economics-ejournal.org/special-areas/replications-1}}, psychology\footnote{\url{https://www.apa.org/pubs/journals/xge/replication-articles}} and neuroscience \citep{Yeung_2017} as well as original research data (e.g. ScientificData\footnote{ScientificData, \url{https://www.nature.com/sdata/}}.

To improve the situation of data availability, \citet{Wilkinson_2016} defined the FAIR Principles, a set of guidelines to achieve sustainable data and metadata management. The four key objectives are to make research data
\begin{quote}
\begin{description}
 \item[F]indable by generating unique and persistent identifiers for data and metadata files. This include the generation of a comprehensive metadata collection, clearly linked to the data via the identifier and vice versa. This way datasets and corresponding metadata can be registered and indexed and are findable via search queries.
 \item[A]ccessible by making data and metadata retrievable via their unique identifier in a standardized way. The applied standards and protocols should be open, free and universal and the accessibility of either data or metadata should not depend on the availability of the other. 
 \item[I]nteroperable by using standardized, broadly applicable tools and language for knowledge representation. This includes using FAIR terminology and providing qualified references to other metadata.
 \item[R]eusable by providing comprehensively described data and metadata including a clear license statement, detailed provenance information using community standards. 
\end{description}
\end{quote}
 Complementing these guidelines, a number of sites have become available for hosting scientific data (Zenodo\footnote{Zenodo, \url{https://zenodo.org/}}, figshare\footnote{figshare, \url{https://figshare.com/}}, Pangaea\footnote{Pangaea, \url{https://www.pangaea.de}}, BMC Research Notes\footnote{BMC Research Notes, \url{https://bmcresnotes.biomedcentral.com/} \& \url{https://bmcresnotes.biomedcentral.com/about/introducing-data-notes}}, DataDryad\footnote{DataDryad, \url{https://datadryad.org/}}, GIN\footnote{GIN, \url{https://gin.g-node.org/}}, EuDat\footnote{EuDat, \url{https://eudat.eu/}}, Research Data Australia\footnote{RDA, \url{https://www.ands.org.au/online-services/research-data-australia/rda-registry}}, see also \citet{Assante_2016}) and publishing data descriptor papers (ScientificData\footnote{ScientificData, \url{https://www.nature.com/sdata/}}, DataScience\footnote{DataScience, \url{https://datascience.codata.org/}}, see also \citet{Candela_2015}).
It has been shown that mandated data archiving upon publication highly improves data availability \citep{Vines_2013}. However, a central prerequisite for the usability of the dataset is the existence of a comprehensive metadata collection \citep{Ferguson_2014,Parekh_2015,Ascoli_2017}. Going one step further, \citet{Chen_2019} show that making only the data (and metadata) available is not sufficient for reproducible science but rather, data also need to be accompanied by software packages used for further analysis. In the optimal case this encompasses a detailed, step-wise description of the motivation for an analysis workflow. \citet{Jomhari_2017} demonstrate that even for datasets surpassing commonly available hardware capabilities (e.g., due to memory limitations), e.g. from particle physics, making the effort of publishing the data is possible and can lead to successful reuse of the data.

The publication of a dataset adhering to the FAIR principles involves a number of concepts, but also technical tools to enable this process. To demonstrate what this entails in practice, here we report on our initial efforts to establish such knowledge for electrophysiology data in the context of the workflows established for a concrete data publication, and discuss critically that implementation. We provide an example of two complex published datasets from the field of neuroscience \citep{Brochier_2018}, demonstrating the richness of data and metadata involved in such an experiment and the concepts to prepare the data for analysis and publication. We present the pipeline used for metadata aggregation and discuss its strengths and shortcomings. Parts of the conceptual underpinnings of the pipeline are published in \citet{Zehl_2016} where they serve as example cases for metadata handling practices. In the following we describe the published datasets based on \citet{Brochier_2018}.



% \section{Publication of two complex electrophysiological datasets}
In \citet{Brochier_2018} we publish two complete high-dimensional electrophysiological datasets containing Utah Array recordings from monkey motor cortex. Recording subjects are two macaque monkeys (monkey L and N) which performed a complex instructed delayed reach-to-grasp task. Each recording contains continuously sampled data from 96 electrodes accompanied by the corresponding spiking activity. Spikes were extracted during online recording and offline sorted using the \software{Plexon Offline Sorter}\footnote{Plexon Offline Sorter, \url{https://plexon.com/products/offline-sorter/}}. Electrophysiological data are accompanied by a number of behavioral and control signals. Detailed metadata were aggregated and are provided in the \software{odML} format (see \cref{sec:intro,sec:scidata_metadata_structure}).

Complex datasets, as the two provided here (high-dimensional, multi-scale during complex behavior), are a challenge for performing reproducible analysis. Besides the often rather variable nature of the circumstances under which such data were recorded, the data additionally experience a number of often interactively performed preprocessing steps before they can be used in actual data analyses. Without a detailed knowledge about all these steps, the actual data analysis may be biased or strongly affected. In most cases, electrophysiological data available as open source are in this respect not sufficiently annotated and documented. For this reason, we provide here a comprehensive description of how and under which circumstances the datasets were recorded as well as a detailed description of preprocessing steps that need to be considered before performing analyses on the data. We additionally publish a machine-readable format of these metadata including our parameters and results of the described preprocessing steps. We are aware that all this information may not be sufficient for the reproducible analysis of such data. The reason is that reproducible workflows including the provenance trail are not yet established for electrophysiological neuroscience, especially not for such complex experiments as presented here.

\section{Relevance to the field}
The published datasets contain rare, multi-channel recordings from a complex electrophysiological setup. There are very few datasets of this type of experiment with this level of complexity available\footnote{published datasets from Utah array recordings in ScientificData: 1 \citep{Brochier_2018}, CRCNS.org: 1 (only spiking activity); date of access: 30 August 2019}, wherefore we provide a valuable addition to the collection of openly available datasets. The datasets are interesting for multiple reasons and can be used in a variety of contexts:
\begin{itemize}
 \item Public datasets are of high value for teaching and demonstration purposes. Especially for teaching it is important to not only work with toy examples, but having real-world data at hand. This improves the teaching quality and provides a better insight into the field. For teaching advanced analysis methods that analyze the correlative properties of neuronal dynamics, corresponding parallel data is essential, such as the provided dataset.
 \item For analysis of coordinated population activity of neural networks in the form of the local field (LFP) potential \citep{Mitzdorf_1985, Logothetis_2004, Einevoll_2013}, this datasets provides the opportunity to study LFP activity exhibiting wave activity across a spatially extended volume of cortex \citep{Denker_2018}.
 \item The datasets contain spiking activity from approximately 100 neurons recorded simultaneously. This permits analysis of coordinated spiking activity, e.g. via correlation analysis techniques \citep{Torre_2016, Torre_2016a, Quaglio_2017, Quaglio_2018}.
 \item The availability of LFP as well as spiking data invites to study the relation between the two modalities, e.g. by relating synchrony in spiking activity to beta band power in the LFP \citep{Denker_2011}.
 \item Additionally to spiking and LFP data the dataset is also rich in behavioural aspects, since the monkey is performing a complex commonly investigated delayed reach-to-grasp task \citep{Smeets_2019,Runnarong_2019}. These datasets provide the opportunity to relate the previously described neuronal analysis to the behaviour of the animal.
 \item The published datasets can serve as first application target for the development of new analysis methods for LFP and spiking activity. Especially needed are e.g. analysis methods applicable to hundreds and more simultaneously recorded spike trains since recent technical development rapidly increases the number of electrodes that can be recorded from in parallel. Most currently available methods are already approaching limits with respect to their demands for compute time and memory with current datasets due to combinatorial explosion \citep{Seo_2015,Jun_2017}. An example of methods that overcome combinatorial issues are dimensionality reduction methods like Gaussian-Process Factor Analysis (GPFA) \citep{Yu_2009}. 
 \item The published datasets together with the detailed description of metadata sources can serve as a template for development of a comprehensive metadata tracking system for neuroscientific experiments. Parts of this development are presented in later sections of this manuscript.
 \item The the correct identification of spikes based on a continuous recording trace (spike sorting) is a field of active research \citep{Rey_2015, Lefebvre_2016, Sukiban_2019}. For the evaluation of spike sorting algorithms, the availability of testing data is critical. With this dataset we provide raw recording traces, automatically extracted threshold crossing events as well as a manual spike sorting to compare new spike sorting algorithms to.
\end{itemize}


\section{The experiment}
The experiment is a delayed reach-to-grasp task performed by macaque monkeys. The basic components of the experiment are displayed in \cref{fig:r2g_introduction}. The monkeys are trained to attend two cues coding for the grip type and force to perform. After the second cue the monkey performs the movement, pulls the object and holds it to receive a reward. At the same time neuronal activity is recorded from motor and premotor areas of the cortex via a chronically implanted Utah Array. 

The subjects of the published datasets are two Rhesus macaque monkeys (Macaca mulatta) which were trained to perform the delayed reach-to-grasp task prior to implantation of the recording arrays. Details on the two subjects are summarized in \cref{tab:scidata_data_overview}. Depending on the monkey character and learning abilities, the different instruction steps (accustoming to the experimenter, setup, different versions of the task) require multiple months of daily training. The training was completed when the monkey had an average success rate of 85\% of the trials in the standard task setting.
The two monkeys trained for the task differ in gender, active hand of the task and character resulting in different behaviours observed during the recording task. As monkey N is rather calm and less motivated he is in general performing shorter sessions and less trials per session as monkey L, who is eager to work (see \cref{tab:scidata_data_overview}). A recording day typically consisted of multiple recording sessions, whereas each session lasts between $10$ and $20$ minutes resulting in an average working time per weekday of $1.5$ hours. Weekends and holidays were usually excluded from training and recording.

\begin{table}[]
\scriptsize
\centering
\begin{tabular}{llllllll}
\hline
                                                                                              & \multicolumn{3}{l}{\textbf{monkey L}}                                                                   & \multicolumn{3}{l}{\textbf{monkey N}}                                                            & \textbf{description}                                                                             \\ \hline
\multicolumn{8}{l}{\textbf{Monkey}}                                                                                                                                                                                                                                                                                                                                                                           \\ \hline
gender                                                                                        & \multicolumn{3}{l}{female}                                                                              & \multicolumn{3}{l}{male}                                                                         &                                                                                                  \\ 
birth date                                                                                     & \multicolumn{3}{l}{15th March 2004}                                                                     & \multicolumn{3}{l}{15th May 2008}                                                                &                                                                                                 \\ 
weight                                                                                        & \multicolumn{3}{l}{5kg}                                                                                 & \multicolumn{3}{l}{7kg}                                                                          &                                                                                                  \\ 
active hand                                                                                   & \multicolumn{3}{l}{left}                                                                                & \multicolumn{3}{l}{right}                                                                        &                                                                                                  \\ 
character                                                                                     & \multicolumn{3}{l}{\begin{tabular}[c]{@{}l@{}}eager to work\\ quick\\ efficient\\ nervous\end{tabular}} & \multicolumn{3}{l}{\begin{tabular}[c]{@{}l@{}}slow learner\\ calm\\ less motivated\end{tabular}} &                                                                                                  \\ 
Utah array rotation                                                                           & \multicolumn{3}{l}{216$^\circ$}                                                                          & \multicolumn{3}{l}{239$^\circ$}                                                                   &                                                                                                \\ \\ \hline
\multicolumn{8}{l}{\textbf{Recording}}                                                                                                                                                                                                                                                                                                                                                                        \\ \hline
session name (*)                                                                              & \multicolumn{3}{l}{\textbf{l101210-001}}                                                                & \multicolumn{3}{l}{\textbf{i140703-001}}                                                         &                                                                                                  \\ 
session files                                                                                 & *.ccf                                  & \multicolumn{2}{l}{108.2 kB}                                   & *.ccf                                & \multicolumn{2}{l}{187.1 kB}                              & cerebus configuration                                                                            \\ 
                                                                                              & *.nev                                  & \multicolumn{2}{l}{287.7 MB}                                   & .nev                                 & \multicolumn{2}{l}{168.3 MB}                              & \begin{tabular}[c]{@{}l@{}}digital events\\ unsorted spikes times\\ spike waveforms\end{tabular} \\ 
                                                                                              & *-02.nev                               & \multicolumn{2}{l}{287.7 MB}                                   & *-03.nev                             & \multicolumn{2}{l}{168.3 MB}                              & \begin{tabular}[c]{@{}l@{}}digital events\\ sorted spikes times\\ spike waveforms\end{tabular}   \\ 
                                                                                              & *.ns2                                  & \multicolumn{2}{l}{8.5 MB}                                     & *.ns2                                & \multicolumn{2}{l}{204.7 MB}                              & \begin{tabular}[c]{@{}l@{}}analog signals of sensors\\ LFP (only monkey N)\end{tabular}   \\ 
                                                                                              & *.ns5                                  & \multicolumn{2}{l}{4.1 GB}                                     & *.ns6                                & \multicolumn{2}{l}{5.8 GB}                                & raw neuronal signal                                                                              \\ 
                                                                                              & *.odml                                 & \multicolumn{2}{l}{2.7 MB}                                     & *.odml                               & \multicolumn{2}{l}{2.3 MB}                                & metadata                                                                                         \\ 
recording start                                                                               & \multicolumn{3}{l}{Fr, 10th Dec 2010 10:50am}                                                           & \multicolumn{3}{l}{Th, 3rd Jul 2014 10:41am}                                                     &                                                                                                  \\ 
recording duration                                                                            & \multicolumn{3}{l}{11:49 min}                                                                           & \multicolumn{3}{l}{16:43 min}                                                                    &                                                                                                  \\ 
daily recording id                                                                            & \multicolumn{3}{l}{1}                                                                                   & \multicolumn{3}{l}{1}                                                                            &                                                                                                  \\ 
\begin{tabular}[c]{@{}l@{}}number of recordings\\ same day\end{tabular}                       & \multicolumn{3}{l}{9}                                                                                   & \multicolumn{3}{l}{3}                                                                            &                                                                                                  \\ 
\begin{tabular}[c]{@{}l@{}}total daily \\ recording time\end{tabular}                         & \multicolumn{3}{l}{01:28 h}                                                                             & \multicolumn{3}{l}{00:51 h}                                                                      &                                                                                                  \\ \\ \hline
\multicolumn{8}{l}{\textbf{Performance}}                                                                                                                                                                                                                                                                                                                                                                      \\ \hline
\begin{tabular}[c]{@{}l@{}}recorded trials\\ (total/error/\\ grip error/correct)\end{tabular} & \multicolumn{3}{l}{204}                                                                                 & \multicolumn{3}{l}{160}                                                                          &                                                                                                  \\ 
\begin{tabular}[c]{@{}l@{}}trials performance\\  correct/error (grip error)\end{tabular}      & 135                                    & \multicolumn{2}{l}{69 (12)}                                    & 135                                  & \multicolumn{2}{l}{19 (16)}                               &                                                                                                  \\ 
\begin{tabular}[c]{@{}l@{}}trial types\\  SG-LF/SG-HF\end{tabular}                            & 41                                     & \multicolumn{2}{l}{30}                                         & 35                                   & \multicolumn{2}{l}{35}                                    &                                                                                                  \\ 
\begin{tabular}[c]{@{}l@{}}trial types\\  PG-LF/PG-HF\end{tabular}                            & 31                                     & \multicolumn{2}{l}{33}                                         & 35                                   & \multicolumn{2}{l}{36}                                    &                                                                                                  \\ \\ \hline
\multicolumn{8}{l}{\textbf{Spike sorting}}                                                                                                                                                                                                                                                                                                                                                                     \\ \hline
\# SUA                                                                                        & \multicolumn{3}{l}{93}                                                                                  & \multicolumn{4}{l}{156}                                                                                                                                                                             \\ 
\# MUA                                                                                        & \multicolumn{3}{l}{49}                                                                                  & \multicolumn{4}{l}{19}                                                                                                                                                                              \\ 
\# electrodes with SUA                                                                        & \multicolumn{3}{l}{65}                                                                                  & \multicolumn{4}{l}{78}                                                                                                                                                                              \\ 
\begin{tabular}[c]{@{}l@{}}\# electrodes with \\     SUA or MUA\end{tabular}                  & \multicolumn{3}{l}{86}                                                                                  & \multicolumn{4}{l}{89}                                                                                                                                                                              \\ \hline
\end{tabular}
\caption[Overview of subjects and recording sessions]{Overview of monkeys, recording session files and dates, spike sorting and monkey performance. The monkeys differ in gender, age, weight and active hand used for the task. Information is provided about individual recording files, sessions, performance of the monkey as well as single unit (SUA) and multi unit activity (MUA).}
\label{tab:scidata_data_overview}
\end{table}

\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{figures/scidata_experiment}
\caption[Components of the Reach-to-Grasp experiment]{Components of the Reach-to-Grasp experiment. A) The monkey is located in a monkey chair, his active hand resting the home position (left panel). The monkey performs an instructed, delayed reach towards an object. Two grip conditions (side grip/precision grip (SG/PG, respectively)) can be instructed via visual cues. B) Visual cues are presented via five LEDs located at the height of the monkeys eyes. The monkey initialized a trial by holding the home switch with his active hand for $400$ milliseconds, then the central LED is activated and stays active for the complete trial. Two complementary cues are presented with a delay of $1000$ milliseconds, coding for the grip type and the force needed to move the object. The of the four corner LEDs, always two neighboring ones are activated. The two vertical arrangements code for the grip type and the horizontal ones for the force type. After the second cue (GO-ON), the monkey releases the home switch (SR-ON), reaches for the object (hold start, HS) and holds it for $500$ milliseconds. Then a reward is delivered and the monkey can initiate the next trial by returning to the resting configuration and holding the home switch again. C) The data acquired during a recording session comprise neural activity signals, as well as behavioral and control signals. Metadata is captured in multiple formats, encompassing hard- and software components and settings as well as information about the subject and post-processing steps performed on the the data. Figure modified from \citet{Brochier_2018}.}
\label{fig:r2g_introduction}
\end{figure}

\begin{figure}
 \centering
 \includegraphics[width=0.65\textwidth]{./figures/scidata_figures/array_placements}
 \caption[Implant locations of the Utah arrays]{Implant locations of the Utah arrays. The figure displays the anatomical location of the Utah Array of both monkeys after implantation as well as the fabrication settings of each array provided by Blackrock. (a) Schematic drawing of a macaque cortex with implant location of the array of both monkeys. Both arrays were implanted along the central sulcus and overlapping the putative border (dotted line) between primary motor cortex (M1) and dorsal or ventral premotor cortex (PMd or PMv) of the right hemisphere. (b, d) Exact location of the array for each monkey in the close-up picture of the implantation site taken during the surgery (length of an array side is $4\textnormal{mm}$). The central sulcus, the arcuate sulcus and the superior precentral dimple are emphasized as thick black lines (to the left, right and top, respectively). (c, e) Scheme of each array in a default array orientation where the wire bundle (indicated with white triangles in (b-e)) to the connector points to the right. Each array scheme shows the 10-by-10 electrode grid with the electrode identification numbers (IDs) defined by Blackrock (black numbers) and the location of the non-active electrodes (indicated in black as $ID=-1$). Gray numbers show an alternative set of connector-aligned electrode IDs, assigned based on electrode location with respect to the connector of the array, which are more practical for data analysis and comparisons across monkeys. In order to best cover the arm/hand representation of the primary motor cortex, each array was rotated for the implantation. The center of rotation is indicated by a colored triangle (b-e), stating below (in c and e) the degree of rotation for each array.}
 \label{fig:implant_locations}
\end{figure}

For recording of neural activity, each monkey had a single Utah array\footnote{Blackrock Microsystems, Salt Lake City, UT, USA} implanted in the motor cortex contralateral to the active hand. The Utah array is an electrode array with 100 electrodes arranged in a $10\times10$ grid. 96 of 100 of the iridium coated electrodes can be used for recording (\cref{fig:implant_locations}). The individual electrodes are $1.5\textnormal{mm}$ long, $400\mu\textnormal{m}$ apart and have an average pre-implantation impedance of $50\textnormal{k}\Omega$. The electrode array is connected to a head stage via a fiber bundle connecting individual electrodes to the contact of the CerePort Connector, which is a connector external to the skin permitting the daily coupling of the implant to the recording setup. In addition to the array electrodes one ground and two reference electrodes are implanted. During the implantation surgery the skull was opened and the dura removed to pneumatically insert the Utah array into the cortex. The dura and skull were close, whereby the cables were arranged to lead to the connector which was attached to the skull on the other hemisphere. The Utah arrays were implanted a few millimeters anterior to the central sulcus and they were rotated before implantation to cover the arm/hand representation of the primary motor cortex as well as parts of premotor cortex (\cref{fig:implant_locations}).

The task the monkeys had to perform involved grasping an object using one of two grip types: side (SG) or precision grip (PG). Detailed sketches of the different grips are depicted in   \cref{fig:r2g_introduction}A center and top panel. For both grip types the position of thumb (T), index (I) and middle (M) finger are indicated relative to the profile of the object. The force required to pull the object towards the monkey was either about $1\textnormal{N}$ (low force) or $2\textnormal{N}$ (high force).  In a trial the monkey was always instructed by the first cue (CUE) about the grip type (SG/PG) and with the second cue (GO) about the force level (LF/HF), resulting in 4 different trial types (SGLF, SGHF, PGLF, PGHF) possible (\cref{fig:task_trialscheme}). The first and second cue are presented with $1\textnormal{s}$ delay in which the monkey has to memorize the presented grip type and can prepare for the movement, which can be initialized after the second (GO) cue. Cues are presented by combinations of two of five illuminated LEDs. The encoding of the grip and force type can be seen in \cref{fig:r2g_introduction}B (CUE-ON and GO-ON). The setup consisted of three main parts, the neural recording platform for acquisition of neuronal signals, the experimental apparatus providing the environment for performing the task and the behavioral control system controlling and coordinating the task procedure (\cref{fig:scidata_setup_overview}, see also \cref{sec:experimental_apparatus}).

\paragraph{Differences between the datasets}
In principle, the same setup was used for both monkeys, however, small deviations exist which are highlighted in the corresponding \cref{fig:implant_locations,fig:scidata_setup_overview,fig:cerebus_system} in yellow (monkey L) and red (monkey N). The four main aspects are
\begin{description}
 \item[Recording Arrays] The datasets are recorded using different Utah arrays. This includes a different electrode mapping as well as a different implant location.
 \item[Connecting Hardware] Usage of different hardware for connecting the implant with the data acquisition system. The two headstages (samtec/patient cable) influence the recording quality by their specific electrical properties.
 \item[Software versions and settings] The recording software versions and setting differ, since an update was available between the recordings. This includes the usage of different file extensions for recordings of continuous data (ns5 in monkey L vs ns6 in monkey N) and additionally a downsampled and filtered version of the neural data being recorded in parallel in the ns2 format for monkey N, which was not available by the software for monkey L. Furthermore the number of samples extracted online for each of the threshold crossing events was increased from 39 samples in monkey L to 48 samples in monkey N.
 \item[Experiment Control] The LabView program controlling and monitoring the task was updated which leads to the usage of different binary coding for digital events (\cref{tab:bit_translation}). 
\end{description}

After the recordings, a number of preprocessing steps (pre in the sense of before the actual upcoming data analysis, but being the post-processing after the recording) were performed. This includes (i) the translation of the digital events from a bit code to a human-readable format, by putting the events in context of the expected executed trial event sequence, (ii) the offline detection of behavioral trial events and object load force from the analog signals, and (iii) the offline spike sorting.

In addition to the preprocessing steps that needed to be performed to gain more content of the raw data, some technical validations of the data also had to be conducted (see also \cref{sec:technical_validation}). These technical validations include the correction of the irregular alignment data files of the recording system and a general quality assessment of the data. In order to validate the quality of the recording, a series of algorithms were applied to the data. On the one hand the quality of the LFP signals was assessed per electrode and per trial by evaluating the variance of the corresponding signal in multiple frequency bands. On the other hand the quality of the offline sorted single units (\cref{sec:offline_spike_sorting}) was determined by a signal-to-noise measure. In addition, noise artifacts occurring simultaneously in the recorded spiking activity were detected and marked.


\begin{figure}
 \centering
 \includegraphics[width=0.8\textwidth]{./figures/scidata_figures/task_trialscheme}
 \caption[Overview of the experimental apparatus and behavioral control system.]{Overview of the experimental apparatus and behavioral control system. (a) Sketches of the experimental apparatus and the monkey performing the reach-to-grasp task. Left: monkey in its home position with the working hand on the table switch. Middle and right: monkey grasping the object with a side grip (SG) and a precision grip (PG), respectively. Insets of middle and right sketch show the actual position of the index finger (I), the thumb (T), and the middle finger (M) on the object (brown cube) 11 . (b) Trial scheme of an example trial with
the respective visual cues (different illumination combinations of the 5 LEDs illustrated on top) shown to the monkey at its respective times. The behavioral events are marked along the time axis (see main text for abbreviations). \code{Event}s with black font mark digitally recorded events, whereas events with brown font indicate events (object touch OT, object release OR, displacement onset DO, and object back to baseline OBB) which were extracted offline from baseline deviations of the analog signals of the object’s sensors. Additionally, we indicate by italic fonts events which were generated by the monkey, while all other events are produced by LabView. The 8-bit binary code for the digital event signals sent from LabView VI to the NSP at the respective times is shown below the time axis. Example traces for the analog signals of the HE sensor (Displ; dark solid line) and one of the 4 FSR sensors located at the object’s surface (GF pr2, light dotted line) used to monitor the monkeys behavior and extract
OT, OR, DO, and OBB are shown at the bottom. (c) Outline of the devices and their wiring controlling the behavior. All analog signal streams are colored in brown, whereas all digital signal streams are colored in black.}
\label{fig:task_trialscheme}
\end{figure}

\begin{figure}
 \includegraphics[width=\textwidth]{./figures/scidata_figures/setup_overview}
 \caption[Overview of the setup]{Overview of the setup. The setup consisted of three main parts: the neural recording platform, the experimental apparatus, and the behavioral control system. The neural recording platform (top) was composed of the implanted Utah array with its corresponding connector (CerePort), a headstage (Samtec or Patient cable), and the Cerebus data acquisition (DAQ) system (i.e. the Front-End Amplifier, Neural Signal Processor (NSP), and the Cerebus control software, Central Suite, installed on the setup computer 1). The experimental apparatus (bottom left) consisted of the physical devices which the monkeys had to interact with (i.e., the visual cue panel (square with 5 LEDs), the target object, the table switch, and the reward system). The behavioral control system (bottom right) was built from hard- and software of National Instruments (NI, National Instruments Corporation, Austin, Texas, USA). It was composed of a NI connector block which was linked via a NI 6023E A-D converter card to setup computer 2 on which the NI system design software, LabView, was running. To record the behavioral data the behavioral control system was interlinked with the neuronal recording platform via the NSP and the NI connector block. All three parts are separately described in more detail in the main text, as well as Figures 2 and 4. Setup differences between the two monkeys are indicated in yellow and red for monkeys L and N, respectively.}
 \label{fig:scidata_setup_overview}
\end{figure}

\begin{table}[]
\scriptsize
\begin{tabular}{|l|llllllll|l|c|l|}
\hline
\textbf{\begin{tabular}[c]{@{}l@{}}decimal\\ code\end{tabular}} & \multicolumn{8}{c|}{\textbf{(8-bit) binary code}}                                                                                                                                                                           & \multicolumn{3}{c|}{\textbf{trial interpretation}}                                                 \\ \hline
                                                                & bit 7         & bit 6                           & bit 5           & bit 4       & bit 3                            & bit 2                            & bit 1                            & bit 0                            & \multicolumn{2}{l|}{}                                                                     & monkey \\ \hline
\textbf{65296}                                                  & 0             & 0                               & 0               & 1           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{l|}{\textbf{TS-ON}}                                                       & L,N    \\ \hline
\textbf{65280}                                                  & 0             & 0                               & 0               & 0           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{l|}{\textbf{TS-OFF}}                                                      & L      \\ \hline
\textbf{65344}                                                  & 0             & 1                               & 0               & 0           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{c|}{\multirow{2}{*}{\textbf{WS-ON}}}                                      & L      \\ \cline{1-9} \cline{12-12} 
\textbf{65360}                                                  & 0             & 1                               & 0               & 1           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{c|}{}                                                                     & N      \\ \hline
\textbf{65360}                                                  & 0             & 1                               & 0               & 1           & 0                                & 0                                & 0                                & 0                                & \multirow{2}{*}{\textbf{PG-ON}}                      & \multirow{4}{*}{\textbf{(CUE-ON)}} & L      \\ \cline{1-9} \cline{12-12} 
\textbf{65365}                                                  & 0             & 1                               & 0               & 1           & 0                                & 1                                & 0                                & 1                                &                                                      &                                    & N      \\ \cline{1-10} \cline{12-12} 
\textbf{65354}                                                  & 0             & 1                               & 0               & 0           & 1                                & 0                                & 1                                & 0                                & \multirow{2}{*}{\textbf{SG-ON}}                      &                                    & L      \\ \cline{1-9} \cline{12-12} 
\textbf{65370}                                                  & 0             & 1                               & 0               & 1           & 1                                & 0                                & 1                                & 0                                &                                                      &                                    & N      \\ \hline
\textbf{65344}                                                  & 0             & 1                               & 0               & 0           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{l|}{\multirow{2}{*}{\textbf{CUE-OFF}}}                                    & L      \\ \cline{1-9} \cline{12-12} 
\textbf{65360}                                                  & 0             & 1                               & 0               & 1           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{l|}{}                                                                     & N      \\ \hline
\textbf{65353}                                                  & 0             & 1                               & 0               & 0           & 1                                & 0                                & 0                                & 1                                & \multirow{2}{*}{\textbf{LF-ON}}                      & \multirow{4}{*}{\textbf{(GO-ON)}}  & L      \\ \cline{1-9} \cline{12-12} 
\textbf{65369}                                                  & 0             & 1                               & 0               & 1           & 1                                & 0                                & 0                                & 1                                &                                                      &                                    & N      \\ \cline{1-10} \cline{12-12} 
\textbf{65350}                                                  & 0             & 1                               & 0               & 0           & 0                                & 1                                & 1                                & 0                                & \multirow{2}{*}{\textbf{HF-ON}}                      &                                    & L      \\ \cline{1-9} \cline{12-12} 
\textbf{65366}                                                  & 0             & 1                               & 0               & 1           & 0                                & 1                                & 1                                & 0                                &                                                      &                                    & N      \\ \hline
\textbf{65385}                                                  & 0             & 1                               & 1               & 0           & 1                                & 0                                & 0                                & 1                                & \multirow{2}{*}{\textbf{SR}}                         & \multicolumn{1}{l|}{(+LF)}         & L,N    \\ \cline{1-9} \cline{11-12} 
\textbf{65382}                                                  & 0             & 1                               & 1               & 0           & 0                                & 1                                & 1                                & 0                                &                                                      & \multicolumn{1}{l|}{(+HF)}         & L,N    \\ \hline
\textbf{65509}                                                  & 1             & 1                               & 1               & 0           & 0                                & 1                                & 0                                & 1                                & \multirow{2}{*}{\textbf{RW-ON}}                      & \multicolumn{1}{l|}{(+CONF-PG)}    & L,N    \\ \cline{1-9} \cline{11-12} 
\textbf{65514}                                                  & 1             & 1                               & 1               & 0           & 1                                & 0                                & 1                                & 0                                &                                                      & \multicolumn{1}{l|}{(+CONF-SG)}    & L,N    \\ \hline
\textbf{65376}                                                  & 0             & 1                               & 1               & 0           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{l|}{\textbf{GO-OFF/RW-OFF}}                                               & L,N    \\ \hline
\textbf{65312}                                                  & 0             & 0                               & 1               & 0           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{l|}{\multirow{2}{*}{\textbf{STOP}}}                                       & L,N    \\ \cline{1-9} \cline{12-12} 
\textbf{65280}                                                  & 0             & 0                               & 0               & 0           & 0                                & 0                                & 0                                & 0                                & \multicolumn{2}{l|}{}                                                                     & L      \\ \hline
\textbf{65391}                                                  & 0             & 1                               & 1               & 0           & 1                                & 1                                & 1                                & 1                                & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{ERROR}}} & \multirow{2}{*}{(+switch)}         & L      \\ \cline{1-9} \cline{12-12} 
\textbf{65359}                                                  & 0             & 1                               & 0               & 0           & 1                                & 1                                & 1                                & 1                                & \multicolumn{1}{c|}{}                                &                                    & L      \\ \hline
\multirow{2}{*}{}                                               & \textbf{pump} & \textbf{LED}                    & \textbf{switch} & \textbf{TS} & \multicolumn{4}{c|}{\textbf{LED}}                                                                                                         & \multicolumn{3}{l|}{\multirow{2}{*}{}}                                                             \\ \cline{2-9}
                                                                &               & \multicolumn{1}{c|}{\textbf{c}} & \multicolumn{2}{c|}{}         & \multicolumn{1}{c|}{\textbf{bl}} & \multicolumn{1}{c|}{\textbf{tr}} & \multicolumn{1}{c|}{\textbf{tl}} & \multicolumn{1}{c|}{\textbf{br}} & \multicolumn{3}{l|}{}                                                                              \\ \hline
\end{tabular}
\caption[Translation table of 8-bit binary to decimal event codes and their interpretation in a trial context]{Translation table of 8-bit binary to decimal event codes and their interpretation in a trial context. The 8-bit binary event code created by LabView states the activation (bit status 1) and deactivation (bit status 0) of the LEDs of the cue system (c:center, t:top, b:bottom, l:left, r:right), the table switch (switch), the reward pump (pump) or the trial start (TS) internally set by LabView. During each trial the (8-bit binary) status of these devices/settings (cf. bottom row) were sent from LabView to the NSP of the Cerebus DAQ system (Figure 2). There, the event codes were converted to a decimal code of the bit sequence assuming another byte with all bits set to 1 in front. The decimal event codes are found in the nev files with a time stamp. The correct interpretation of these events in context of a trial are here indicated in the second column from the right. Due to different versions of the LabView control program for monkey L and N the decimal codes for the same event may differ between the monkeys (cf. first column from the right). Some event codes (65381, 65386, 65390, 65440, 65504) are not listed here, because they do not have a concrete meaning and occur only sporadically in the nev file due to a mistake in the sampling of the digital events - they have to be ignored. Except for the "ERROR" codes, the event codes are sorted in sequential order from top to bottom with respect to the task, i.e. their order corresponds to the sequence found in the nev file in a reach-to-grasp trial. Note that some events are represented by the same decimal codes and are just differently interpreted due to their sequential occurrence in a trial (cf. TS-OFF and STOP, as well as WS-ON and CUE-OFF).}
\label{tab:bit_translation}
\end{table}


\section{The metadata structure}
\label{sec:scidata_metadata_structure}
All aggregated metadata for a single recording session are collected in a separate \software{odML} file (\cref{tab:scidata_data_overview}). Within an \software{odML} file, information is organized in a hierarchical fashion, following a schema that was defined and continuously refined during the course of the set up of the metadata processing pipeline. \cref{fig:scidata_l101210odml} shows an exemplary part of the metadata collection of the recording session of monkey L. The \software{odML} files contains the following eight top-level sections: \textit{Project} (general information on the reach-to-grasp project), \textit{Subject} (information on the monkey), \textit{Setup} (details of the experimental apparatus), \textit{Cerebus} (settings of the recording system), \textit{UtahArray} (information on the multi-electrode array including spike sorting results and the corresponding quality assessment), \textit{Headstage} (general settings), \textit{Recording} (task settings, trial definitions with event time stamps and periods), \textit{PreProcessing} (results of LFP quality assessment and general information on the spike sorting procedure).
Each top-level \code{Section} contains a branch structure built from \code{Section}s to logically organize the information about the specific aspect of the experiment. For example, the \textit{Subject} \code{Section} contains nine \code{Properties} (denoted by a folder icon), and multiple \code{Section}s beneath, among them for example a  \textit{Training} \code{Section} and \textit{ArrayImplant} \code{Section} (denoted by a collapsible folder icon in \cref{fig:scidata_l101210odml}). All metadata available describing the training of monkey L are the coach (Thomas Brochier), start and end date of the training period (June 2010 - September 2010) and a comment stating that the training was easy and fast. Larger numbers of metadata are stored for describing the recording array used for the recording. Here, the \code{Section} \textit{UtahArray} contains general information about the hardware (material, dimensions, etc) and detailed information about each electrode is contained in the \textit{Electrode} \code{Section}s. Each electrode \code{Section} contains information about the electrode identity and physical location, the impedance value and offline sorting results for data recorded here (not shown in \cref{fig:scidata_l101210odml}). The metadata collection of monkey N has an analogous structure.

\begin{figure}
 \includegraphics[width=\textwidth]{./figures/scidata_odmltree}
 \caption[Schematic metadata collection of session l101210-001]{Schematic metadata collection of recording session l101210-001 as rendered by the GIN webinterface. \code{Properties} are displayed in the form of \code{<Property Name>: <List of Values> (<Property Description>)}. Individual \code{Section}s are unfolded via user interaction to display the underlying metadata structure. Figure modified from \url{https://gin.g-node.org/INT/multielectrode_grasp/src/master/datasets/l101210-001.odml}.}
 \label{fig:scidata_l101210odml}
\end{figure}

\section{Data and metadata processing pipeline}
\label{sec:r2g_preprocessing_pipeline}
The metadata information as described \cref{sec:scidata_metadata_structure} was aggregated from multiple files and formats into a single file in the \software{odML} format (\cref{sec:odml}). This aggregation requires access to, and interpretation of a variety of files and formats, extraction of the corresponding information and integration in the designated location a pre-designed \software{odML} structure. In the pipeline used here (\cref{fig:scidata_metadata_pipeline}), the construction of the \software{odML} structure of a particular recording session is strictly separated from the enrichment of the structure with metadata content. In a first step, an \software{odML} structure with default metadata entries is set up based on multiple Python scripts generating individual branches of the \software{odML} structure. Since the particular structure required for a recording session depends on the specifications of the recording, this process depends to some extend on the metadata to be added (see \cref{fig:scidata_metadata_pipeline}, red arrows). This interdependency requires the metadata to be loaded and partially interpreted prior to the initialization of the structured metadata collection. One example for such a dependency is the existence of spike sorted data after offline spike sorting. Here, first the source files need to be evaluated to extract if the particular session was already sorted to construct the metadata structure accordingly such that it can later accommodate potential spike sorting metadata.

After construction of the \software{odML} structure, metadata information is added via a set of custom enrichment functions, i.e., filling available metadata into the structure. This enrichment process is split into different functions that first extract information from the different specialized metadata source file formats and add this data in the \software{odML} structure. In the enrichment process, the location of the target \code{Property} in the structure is implemented by exploiting the filter functionality of \software{odML}. This way, filling the \software{odML} structure requires no detailed information regarding the \software{odML} hierarchy. This provides some degree of flexibility in dealing with variations in the \software{odML} structure, i.e. for different variations of the task or through the continuous improvement of the structure over the course of the experiment. However, given the large number of metadata values to fill, this is computationally more intense than accessing the target location directly via its hierarchy path. Finally, after building and enriching the metadata collection the \software{odML} file with more than $1300$ \code{Section}s, $8000$ \code{Properties} and about $10000$ \code{Value}s is saved.

Setting up this pipeline required preparatory work on multiple levels:
A) The manual preparation of the \software{odML} structure in form of \software{odML} templates in dedicated Python scripts. These scripts mostly comprise between $700$ and $1700$ lines of code and contain the generation of all \software{odML} \code{Section}s and \code{Properties} including default \code{Value}s, since \code{odML} version 1.3 used at that time requires a minimum of one \code{Value} per \code{Property} (see \cref{sec:odml_model_revision}). 
B) The preparation of the metadata source files in the required format. This involved manual offline spike sorting using the \software{Plexon} spike sorter to generate a sorted \code{nev} file and spike sorting \code{mat} and text files containing the resulting metadata. For a single recording session this process requires a few working hours of a trained scientist. Additionally, xls sheets following the \software{odMLtables} standard needed to be set up containing information about the recording (sub)session, the monkey and the recording setup. Furthermore a single text file providing the mapping spatial systems of electrode IDs used in the experiment (\code{brain\_aligned\_elids.txt}) and the results of three \software{Matlab} based preprocessing scripts for detection of behavioural events based on continuous signals (\code{even time markers} and \code{load detection}) and the quality checks for continuous signals in multiple frequency ranges and electrodes (\code{rejections}) need to be provided. Most of these metadata source files are recording session specific and need to be generated after the recording was performed. Typically, these files are generated by the experimenter, however due to the time required for this manual step and the amount of available data, not all of this information becomes available immediately, possibly only years after the experiment.
C) The implementation of the central script to generate the resulting \software{odML}  (\cref{fig:scidata_metadata_pipeline} \code{odMLGenerator.py}) by combining the \software{odML} structure from the templates with the content of the metadata sources. Implementation of this script needs detailed knowledge about both aspects of the \software{odML} generation process to be able to combine the two.

\begin{figure}
 \includegraphics[width=\textwidth]{./figures/scidata_odMLgeneration_diagram}
 \caption[Schematic metadata aggregation pipeline used in \citet{Brochier_2018}]{Schematic metadata aggregation pipeline used in \citet{Brochier_2018}. The \software{odMLGenerator} script (middle box) accesses \code{odML} templates (left box) and metadata source file in different formats (right box). Based on a configuration file, first the structure of the \code{odML} is set up relying on Python scripted \code{odML} templates. In a second step, the structure is enriched with information content from the metadata files. Information from these files is extracted using a variety of different tools (\code{reachgraspio}, \software{odMLtables}, the Python \software{csv} and \software{sicpy} packages) and added to the pre-built \software{odML} structure via custom enrichment functions to generate the final metadata collection. Setting up the \software{odML} structure requires information about the metadata and the configuration (red arrows), which is extracted from the metadata files prior to the building of the \software{odML} structure.}
 \label{fig:scidata_metadata_pipeline}
\end{figure}

\section{Data loading and enrichment with metadata}
\label{sec:data_loading_and_enrichment}
To benefit from a complete metadata collection in the \software{odML} format when loading the original data the metadata should be made easily accessible in combination with the data. This permits the user to access the complete information available during later processing and analysis steps, e.g. for selection of specific trial time periods or recording signals without artifacts. For this, it is essential to combine the information from the metadata collection with the data as the user otherwise needs to switch between different sources and structures for retrieving information. This would introduce additional, unnecessary dependencies in the processing and analysis code.
We provide the \software{ReachGraspIO} Python class which extends the \software{Neo} data structure upon loading with metadata (\cref{sec:usage}). The \software{ReachGraspIO} inherits from the \software{Neo} \code{BlackrockIO} and exploits its functionality to read data from \code{nsX}\footnote{$X \in \{1,2,3,4,5,6\}$} and \code{nev} file formats (\cref{fig:scidata_reachgraspio_diagram}). It returns a \software{Neo} \code{Block} based on the original structure generated by the \software{Neo} \code{BlackrockIO}. The API to interact with the data is therefore the same when using directly the \software{Neo} \code{BlackrockIO} and the \code{ReachGraspIO}. For a detailed description of the \software{Neo} structure and \code{IO}s, see \cref{sec:neo}.

The application programming interface (API) of the \software{ReachGraspIO} is almost identical to the API of the \software{BlackrockIO}. The \software{ReachGraspIO} uses slightly different default parameters, which are adjusted to the datasets generated by the Reach-to-Grasp experiment. The usage of the \code{ReachGraspIO} is demonstrated in an example Python script, which loads the data and visualizes the recording signals at the time point of a trial start (\cref{code:scidata_visualization_1,code:scidata_visualization_2,fig:scidata_visualization}).
Identification and selection of a trial start event in the recording is facilitated by using the \code{ReachGraspIO} instead of the \code{BlackrockIO} directly as the \code{ReachGraspIO} identifies individual trials while loading the data and labels the trial events in a human readable fashion.


\begin{codeenv}
\inputminted[firstline=68, lastline=82, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\inputminted[firstline=86, lastline=86, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\inputminted[firstline=92, lastline=96, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\inputminted[firstline=99, lastline=119, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\inputminted[firstline=123, lastline=130, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\inputminted[firstline=143, lastline=148, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\inputminted[firstline=159, lastline=166, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\inputminted[firstline=174, lastline=176, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\caption[Example code for loading and processing of published data]{Example code for loading and processing of published data. Metadata annotated data is loaded (line 69-86) and a low pass filtered version of the original signals in generated (line 99-119). Trials are identified and signals are cut into the corresponding segments (line 123-176).  Code extracted from \citet{Brochier_2018}, \url{https://gin.g-node.org/doi/multielectrode_grasp/src/master/code/example.py}}.
\label[codelisting]{code:scidata_visualization_1}
\end{codeenv}

\begin{codeenv}
\inputminted[firstline=195, lastline=253, linenos,tabsize=2,breaklines, fontsize=\fontsize{7}{8}\selectfont]{python}{figures/scidata_figures/example.py}
\caption[Continuation of \cref{code:scidata_visualization_1}: Plotting published data]{Continuation of \cref{code:scidata_visualization_1}. The plotting of the data belonging to the extracted trials for generation of \cref{fig:scidata_visualization}. The figure is initialized and plotting parameters are defined (line 196-199). \code{AnalogSignal}s are visualized (line 201-208) and \code{Spiketrains} are plotted together with the corresponding waveforms (line 213-230). \code{\code{Event}}s are visualized as vertical lines, labelled in human readable way (line 233-242). Finally, the plot is completed and saved in three different formats (line 244-153). Code extracted from \citet{Brochier_2018}, \url{https://gin.g-node.org/doi/multielectrode_grasp/src/master/code/example.py}}.
\label[codelisting]{code:scidata_visualization_2}
\end{codeenv}

\begin{figure}
 \includegraphics[width=\textwidth]{./figures/scidata_figures/example_plot}
 \caption[Example visualization of the published data]{Example visualization of the published data. The code to generate the figure is shown in \cref{code:scidata_visualization_1,code:scidata_visualization_2}. All recorded data from a single electrode are visualized: the raw, high resolution continuous recording signal (ns6, black), the online filtered continuous recording signal (N's, blue) as well as an offline filtered version based on the raw signal (red). In addition spikes times are marked corresponding to their \software{Unit} assignment and online extracted waveforms are plotted (yellow, green and black traces). Trial events are also visualized (dashed vertical line) and labelled in human readable way (TS-ON, gray).}
 \label{fig:scidata_visualization}
\end{figure}

The \software{ReachGraspIO} extends and annotates the \software{Neo} structure generated by the \software{BlackrockIO} in multiple ways: continuous recording signals are corrected for time shifts introduced by online filters, event times extracted from analog signals are added and a merged representation of events from digital and analog sources is created (\cref{fig:scidata_reachgraspio_diagram}, red box). The first two of these extensions depend on metadata being provided from the metadata collection in \software{odML} format. Additional annotations based on information from the metadata collection are added to most of the \software{Neo} objects (\cref{fig:scidata_reachgraspio_diagram}, gray box). This includes basic metadata describing individual recording traces of \code{AnalogSignal}s, sorting information of \code{Unit}s, general metadata for \code{Segment} and \code{Block} objects, as well as information from the offline trial rejection. If no \software{odML} metadata collection is present, these extension and annotation steps are skipped.
Some of these extension and annotation steps require also additional information, which is available within the \code{ReachGraspIO} as metadata lookup tables. These contain experiment specific code mappings which are essential for the interpretation of the data stored in the original \code{Blackrock} data files. This includes the mapping of bit-coded to human readable notation for events required to define a trial, event codes and equivalence groups, the mode in which the experiment is running (experimental conditions) as well as the performance codes standing for the outcome of a trial attempt (\cref{fig:scidata_reachgraspio_diagram}, green box). These metadata lookup tables are used to translate the bit-based encoding of trial events into human readable versions. If an \code{odML} file is available, trial ids are extracted from there and also annotated. This interpretation of the events is a prerequisite for two further annotation steps: the identification of the task condition, i.e., the task paradigm used in the recording, which again uses a \code{ReachGraspIO} lookup table, as well as the annotation of rejected trials. If digital and analog events are present, these will be merged in to a single \code{\code{Event}} object to simplify the access to all events of recording session (\cref{fig:scidata_reachgraspio_diagram}, 'merge digital \& analog events'). Finally the \code{ReachGraspIO} returns the modified \code{Block} which can be used in further data analysis and visualization scripts (e.g. see \cref{code:scidata_visualization_1,code:scidata_visualization_2}) or in the generation of a metadata collection (see \cref{fig:scidata_metadata_pipeline}).

\begin{figure}
 \includegraphics[width=\textwidth]{./figures/scidata_reachgraspio_diagram}
 \caption[Schematic data loading pipeline used in \citet{Brochier_2018}]{Schematic data loading pipeline used in \citet{Brochier_2018}. The \software{ReachGraspIO} (central box) utilizes the \software{BlackrockIO} of \software{Neo} to load the original recording data (top right). In a second step it enriches and extends the data structure returned by the \software{BlackrockIO} containing uninterpreted row data based on additional metadata information from two sources: a metadata collection in \software{odML} format (blue) and ReachGraspIO internal lookup tables (green) containing the essential information required for interpretation the data from the original data files. The extension of the \software{Neo} structure includes correction of time shifts of the recording signals, addition of events which were extracted offline from behavioural signals and the merging of multiple event arrays containing meaningful, human readable events in the trail ('correct filter shifts', 'add analog events' and 'merge digital \& analog events', respectively; red box). The enrichment of the \software{Neo} structure encompasses the addition of numerous annotations (gray box). If no metadata collection is found, these steps are skipped. Finally the extended \software{Neo} structure is returned and can be used for the generation of a metadata collection or further processing and analysis steps. This introduces a circular dependency between the \software{ReachGraspIO} and the metadata collection, as the first one can use the other if present to add trial ids as annotations to the \software{Neo} structure, but also the \software{odML} generation depends on the \software{ReachGraspIO} as essential metadata is annotated based on internal lookup tables (see also \cref{fig:scidata_metadata_pipeline}). Relations contributing to this circular dependency of metadata are marked by red arrows.}
 \label{fig:scidata_reachgraspio_diagram}
\end{figure}




The original pipeline was implemented using Python 2 and \software{odML} version 1.3. The published datasets were updated in 2019 to be compatible with Python 3 and \software{odML} version 1.4. Old versions are still accessible via the published DOI\footnote{10.12751/g-node.f83565, \url{https://gin.g-node.org/doi/multielectrode_grasp}} and the version control system of GIN\footnote{GIN, \url{https://web.gin.g-node.org/}}.

\section{Shortcomings of the \software{odML} generation pipeline}
\label{sec:scidata_shortcomings}
% August 2019: 1974 datasets available at /datasets/marseille/congloue/data/DataGrasp
The presented data publication demonstrates the complexity of the datasets and the efforts required for preparation and release of the data. The complexity of the process is exemplified by the fact that only two of of almost 2000 recording sessions being performed in total with five monkeys were fully described at the time of publication. Here we list reasons we identified that complicate the preparation process:

% additional features in other datasets
\paragraph{Additional features}
\label{sec:additional_features_gaps}
Describing two datasets in a high degree of detail in a manuscript requires 23 pages of descriptor to provide all necessary details. Including additional datasets following the same experimental paradigm would expand the descriptor as additional features observed in the data need to be described. Extending the descriptor to include all peculiarities of all datasets will confuse the reader therefore make the dataset less easily reusable. Moreover, even small additions or changes in the data and metadata processing may result in substantial changes to the pipeline design.
An example for additional features which would require explicit description is an additional type of artifact, which is not described in \citet{Brochier_2018} as these two datasets do not exhibit unintended gaps during the recording (\cref{fig:scidata_gaps}). This type of artifact was first described in \citet{Sprenger_2014} and occurs when individual data packets are lost during data recording within the recording hardware. The loss of data packets does not cause an interruption of the recording and is not tracked in the recording file, but the recording files appear intact. Lost data packets can only be detected afterwards by comparing raw continuously recorded data with the corresponding threshold crossing events detected online during recording. After the occurrence of a lost data packet, these two signal are not aligned, as only the continuous signal is affected by lost data packages, and not the threshold crossing events.
For a comprehensive check for gaps during the recording, the \software{odML} generation pipeline would need to be extended in multiple places: Firstly, an additional \code{Section} in the \software{odML} structure would be required to capture the details of potential by a function scanning the original data files. This would require changes in the \software{odML} templates (\cref{fig:scidata_metadata_pipeline}, left box). Secondly, an additional function for gap detection by comparing events to continuous signals needs to be integrated in the \software{odML} generator. This requires extension of the \software{odML} generation code and would potentially increase the run time of the code considerably as the comparison for a full dataset can be compute intense and the \software{odML} generation process is not parallelized. Finally, since the coded detection of gaps can only identify the occurrence of a gap, without reliably characterizing the exact time point or exact extend of the gap, a manual inspection of the data with a detected gap is required after the first run of the \software{odML} generator. To reliably document the results of this manual inspection the integration of the results into the \software{odML} file is mandatory. This could be implemented by the manual generation of a secondary metadata source file, from which the corresponding metadata is extracted during the \software{odML} generation process and included in the metadata collection. However, the suggested procedure requires the execution of the complete \software{odML} generation pipeline twice, once for running the coded detection of gaps and once for integrating potential manually generated additional metadata describing the exact gap time and size. The suggested procedure would therefore more than double the run time of the complete \software{odML} generator for recording sessions with gaps, event though only a small fraction of the metadata was added.

\begin{figure}
 \centering
 \includesvg[width=0.7\textwidth, pretex=\relscale{0.8}]{./figures/scidata_gaps_escus}
 \caption[Origin of gaps in continuous recording data]{Origin of gaps in continuous recording data. Depicted are the recording signals as they are send by the Neural Signal Processor (NSP) ('Real Signal', top) and as they are received by the Central Suite computer (CSC) to be written to disc ('Saved Signal', bottom). For a visualization of the hardware components, see \cref{fig:scidata_setup_overview}. The spike times are extracted from the continuous signals by the NSP and the corresponding time of threshold crossing is attached to each spike. In case of a loss of data during the transfer to the CSC, the spike times are unaffected, only the corresponding spikes of the lost data are not present. For the continuous signal however, the loss of data leads to a concatenation of the remaining samples without considering the original time stamps of the data samples as these are not attached to the data packets (compare sample point marked in red). Therefore the continuous signal is shifted with respect to the extracted spikes starting from the beginning of the gap.}
 \label{fig:scidata_gaps}
\end{figure}


% thorough preparation of all preprocessing steps required
\paragraph{Manual validation}
Preparing the data for data publication requires cross checking of all preprocessing steps (e.g. detection and correction of data packet loss) necessary for that particular set of data. However, in the present scenario, such cross-checks are neither automatized if possible, nor proceduralized. Instead they are performed once a specific dataset is selected for a given analysis, and only specific types of cross-checks relevant for the analysis are typically performed by the researcher.

% variability across datasets not covered by published version
\paragraph{Variability across datasets}
The pipeline for automatic metadata aggregation as presented here has been tested extensively for the two datasets published and the generated files have been manually checked. Running the exact same pipeline on different recording datasets from the same recording has been found to frequently fail, due to slight variations between recording sessions. An intuitive example for this is the set of event codes observed within a recording (\cref{tab:bit_translation}). Here, the interpretation of the observed events codes is performed by the \code{ReachGraspIO} transforming combinations and sequences of bit-encoded events to human readable labels. Due to complex sequences of event codes that may arise, the interpretation of the bit codes in this experiment highly depend on the monkey covering scenarios not encountered for the two published datasets. Extending this to other monkeys and other recording sessions required i) extending the interpreting routine making the code more convolved and less readable and ii) extensive manual validations to ensure the correct interpretation of the bit encoded events.

% availability of source files
\paragraph{Availability of source files and pipeline complexity}
The preparation of source files for the metadata aggregation into a single \software{odML} file is laborious and requires thorough cross checking. Typically, there is no dedicated person responsible for this, but the task is shared between people involved in the experiments. This results in a diffusion of responsibility, as all scientists also have individual projects to care about often focused on a specific subset of the data. For the discussed experiment, not all source file are available for all recording sessions, therefore the generation of an \software{odML} file will not succeed for part of the recording sessions. This mainly affects sessions that are currently not used for analysis due to other quality exclusion criteria. Most importantly, the complexity of the \software{odML} generation leads to a situation where most scientists are not able to properly assist in the curation process.
\newline

In addition to the factors complicating the publication of a high volume of additional datasets from the same experiment as above, there are additional challenges to be taken into account when implementing a metadata aggregation pipeline of the complexity as presented here:

\paragraph{Multiple contributors}
In the case of multiple people involved in the curation process this also requires coordinated activity among all of them. Having individual copies of source files and running the metadata aggregation pipeline using different configurations will lead to various, potentially inconsistent metadata collections. Also the updates of metadata need to be tracked and communicated in a reproducible manner.

\paragraph{Robustness \& Usability}
Special attention also needs to be invested making the execution of the pipeline (or minimally: the result of the execution) available to all collaborators, taking into account different needs and software (version) requirements of scientific projects. The pipeline therefore has to be robust to be run on different machines and different system environments and results need to be compatible with all analysis setups in use. For example for the published datasets accessing the data requires consistent \code{ReachGraspIO} and \software{Neo} versions.

\paragraph{Structure \& Reusability} The presented metadata pipeline separates the generation of the structural templates of the \software{odML} and their enrichment with metadata values. This separation is a good approach during the design of the metadata pipeline, as a general structure first needs to be established before implementing the enrichment. During the production phase of the \software{odML} generation, however, this separation results in a coupling between the two phases, as for the enrichment of the \software{odML} structure knowledge about the structure is required. During the runtime of an experimental series frequently also structural adjustments and extensions to the \software{odML} tree need to be performed as the experimental design was updated or the need to track additional metadata was recognised. The modification and extension of the metadata structure during the production phase always requires changes on both ends of the \software{odML} generation process (structure building \& enrichment), leading to an overly complex procedure to adjust the pipeline which is hard to maintain.
Due to the separation of the structural templates and their enrichment with metadata only the template \software{odML} files are easy to extract from the presented pipeline for application in a different experiment. The enrichment of the structure is built-in the \software{odML} generation pipeline and can not be easily transferred to another metadata pipeline as this is code is specific to the metadata source files.

\paragraph{Linearity}
The presented pipeline for generating a metadata collection relies on the usage of the \code{ReachGraspIO} (\cref{sec:data_loading_and_enrichment}) for a basic interpretation of recorded events using the internal metadata lookup tables. Hard coding metadata processing in this manner is a reasonable approach to make the data quickly usable while the experiment is still under development, but in a stable configuration this introduces cyclic dependencies. In the example presented, the \code{ReachGraspIO} relies on an (optional) \software{odML} file to provide metadata on the one side and on the other side the \software{odML} generation process depends on the usage of the \code{ReachGraspIO} (see \cref{fig:scidata_metadata_pipeline,fig:scidata_reachgraspio_diagram}). This introduces additional dependencies between software versions and metadata and convolutes the data loading from metadata interpretation and annotation aspect.

\paragraph{Portability} The presented metadata pipeline relies on specific versions of software packages, whereas typically in an experimental environment the exact versions used are not necessarily well documented in a rigorous fashion. Therefore executing the pipeline on a different system ,e.g., a high performance cluster, requires expert knowledge and additional effort to satisfy all version dependencies of the pipeline with respect to other software packages.

\paragraph{Consistency} Working with the published data requires multiple compatible files to be present: the original data files, the metadata collection, and multiple software packages including multiple custom codes, in particular the \code{ReachGraspIO} and \software{Neo} in combination with \software{odML}. In other words, a researcher must use the same versions of all of these components as was used during the \software{odML} generation process. The version compatibility between all three aspects is typically only neglectfully documented and needlessly complicates the setup of a system to work with the data. Moreover, it locks the users into versions of libraries that may become outdated over time.



\section{Requirements for maintainable and reproducible metadata management}
\label{sec:metadata_requirements}
Based on the experience from publishing the two datasets (\cref{sec:scidata_shortcomings}) we identify essential requirements for maintainable and reproducible metadata management pipelines in complex, collaborative projects.

\begin{description}
 \item[R1: Common terminologies] To have a foundation for communication between collaboration partners it is important to agree on common terminologies. Within a scientific discipline, this might be given to a sufficient degree from mutual understanding, but as soon as scientists from multiple backgrounds need to interact, agreeing on common terms is an essential first step. Formalizing this in a documented way in the metadata collection is part of this process and documents the terminology also for future generations of scientists but also within the run-time of a single project.
 \item[R2: Structured machine \& human readable metadata] The metadata collection needs to be programmatically accessible to be used for data annotation and querying. However, metadata also needs to be human readable, for manual checks and scanning of metadata. This becomes of special importance in the context of laboratory notebooks and how automatically generated metadata collections can substitute the manual notebooks in the long term. Finally, if metadata are machine accessible this information can automatically be used during data processing and analysis (e.g. for labelling in data visualization). However this approach only makes sense if the data is additionally human readable, as in the in the long run scientists inspect the processing and analysis results.
 \item[R3: Central data and metadata location] As discussed in \cref{sec:scidata_shortcomings}, in a collaborative environment a systematic organization of metadata is essential. Providing access to data and metadata via a central data storage is a straight forward solution. 
 \item[R4: Version control] To be able to communicate efficiently about data and metadata, version control can assist in collaborative curation, but also in making changes and addition to metadata visible. Using version control the usage of identical data and metadata versions by different scientists can be guaranteed as well as changes in the data and metadata collection can be tracked easily. This permits to track updates and changes on the data and metadata side and documents these.
 \item[R5: Mostly automatic metadata compilation] With the large amount of metadata accumulating it is a high priority to automate metadata aggregation as far as possible. In some cases this is not possible in all cases, e.g. when metadata are only available in hand-written form in laboratory notebooks. This type of metadata however is a very small fraction of metadata and has to be digitized manually in most cases.
 \item[R6: Extendable metadata workflow] As discussed in \cref{sec:scidata_shortcomings} scientific metadata workflows need to be easily extendable to cope with latest analysis requirements and scientific findings.
 \item[R7: Reusability] Scientific workflows should be (partially) reusable for related projects to simplify the setup of similar workflows and save time in implementing these.
 \item[R8: Standardized \& reproducible preprocessing] Standardizing preprocessing steps improves clarity and rigour of the preprocessing tools and contributes to the aspect of Reusability of the workflow. Making the individual preprocessing steps reproducible e.g. by tracking used packages (provenance tracking) and documenting the code version helps making the whole workflow reproducible.
 \item[R9: Easy to access data and metadata for non-experts] Data and metadata should be easy to use by non-experts of the preprocessing pipeline. In the ideal case an out-of-the-box solution can be presented to the user, who can load the data immediately without installing a series of software dependencies. 
 \item[R10: Consistent data and metadata] Data and metadata should always be consistent. This includes the guarantee that,e.g., preprocessing steps performed on the data should also be reflected in the metadata collection. The concept of version control and reproducibility aid the consistency assurance.
 \item[R11: Open source tools] In as much as possible, the workflow should use open source software tools that provide their source code to the community. This has the advantage of validation of the correct functionality by other users and permits to fix potential errors. For community software projects also code corrections and enhancements can be suggested and will usually be reviewed and integrated into the tool. Open source tools are free of charge and therefore provide a suitable basis for scientific work to be independent of industry.
\end{description}


\subsection{Evaluation of presented metadata pipeline}
\label{sec:r2gpipeline_evaluation}
The pipeline used for metadata aggregation and access in \citet{Brochier_2018} is described in \cref{sec:scidata_metadata_structure}. In \cref{sec:metadata_requirements} we identify a eleven requirements for maintainable and reproducible metadata management. In the following we evaluate the presented pipeline with respect to these requirements. \cref{tab:requirement_check_scidata} summarizes the findings.
\newline

\begin{table}[]
\begin{tabular}{|l|l|}
\hline
Requirement                                          &  \cite{Brochier_2018} \\  \hline
R1: Common terminologies                             &  in project \\ \hline
R2: Structured machine \& human readable metadata    &  yes \\ \hline
R3: Central data and metadata location               &  no \\ \hline
R4: Version control                                  &  no \\ \hline
R5: Mostly automatic metadata compilation            &  manual initialization \\ \hline
R6: Extendable metadata workflow                     &  minimal \\ \hline
R7: Reusability                                      &  partial \\ \hline
R8: Standardized \& reproducible preprocessing       &  no \\ \hline
R9: Easy to access data and metadata for non-experts &  partial \\ \hline
R10: Consistent data and metadata                    &  partial \\ \hline
R11: Open source tools                               &  mostly \\ \hline
\end{tabular}
\caption[Overview of workflow features for \citet{Brochier_2018}]{Overview of workflow features for \citet{Brochier_2018} based on requirements for data and metadata workflows as defined in \cref{sec:scidata_shortcomings}. The presented pipeline fulfills basic criteria regarding common terminology definition and structured and readable metadata and the usage of open source tools. Other criteria are partially or not met.}
\label{tab:requirement_check_scidata}
\end{table}

The presented metadata pipeline consists of two main components: the \ \code{odMLGenerator} for integrating the metadata in a single \software{odML} metadata collection and the \code{ReachGraspIO} for data access and integration with metadata. By utilizing \software{odML} for metadata storage the requirement of having common terminologies (\requirement{R1}) is fulfilled on a project level in this pipeline, since \software{odML} requires the specification and definition of terms within the collection which is then shared between collaborators. This approach also guarantees that the metadata collection is machine and human readable (\requirement{R2}), as the \software{odML} file is xml based and provides tools for user friendly visualization (\software{odMLtables} (\cref{sec:metadata}), odML-UI\footnote{\url{https://pypi.org/project/odML-UI/}}, odml\_view\footnote{\url{https://github.com/G-Node/python-odml/blob/master/odml/scripts/odml_view.py}}).

The pipeline itself does not include the automatic storage of data or metadata or related scripts at a central location (\requirement{R3}). However, combining the pipeline manually with a central server or a common data hosting platforms is straightforward as data as well as metadata files are self contained. By using a central data hosting platform which supports version control, like GitHub\footnote{\url{https://github.com/}}, GitLab\footnote{\url{https://about.gitlab.com/}} or GIN\footnote{\url{https://gin.g-node.org/}}, version control can be automatically introduced at the same time (\requirement{R4}). Alternative to using version control in combination with a remote server, a version control system can also be implemented locally, e.g. by using git\footnote{\url{https://git-scm.com/}}, git-annex\footnote{\url{https://git-annex.branchable.com/}} or git-lfs\footnote{\url{https://git-lfs.github.com/}} to version data locally.

The presented metadata pipeline is automated in the sense that it does not require direct manual interaction (\requirement{R5}). However, a fully automated workflow would include automatic initiation of the pipeline upon a change in the source files. This is not the case here, as there is no trigger mechanism included here. Instead, the pipeline is triggered by the user and can be performed selectively on a subset of available files. The latter is bound to lead to a situation where the metadata collection of the complete experiment becomes inconsistent. Possible extensions including this would be the integration of centrally hosted code in combination with a web hook to a continuous integration service like Jenkins\footnote{\url{https://jenkins.io/}}, Travis\footnote{\url{https://travis-ci.org/}} or CircleCI\footnote{\url{https://circleci.com/}}. In this way adding or modifying metadata sources or the code to generate \software{odML} files in a repository would automatically trigger the \software{odML} generation process.

The extendability (\requirement{R6}) of the presented pipeline is limited, as changes in the metadata always require code changes in multiple locations (see \cref{sec:scidata_shortcomings}, 'Additional features', 'Variability across datasets', 'Structure \& Reusability') and dependencies between structure and metadata need to be explicitly implemented in the \code{odML} generation process. This requires expertise knowledge about experiment, its metadata and the metadata pipeline and leads to convoluted code due to the monolithic design of the pipeline.

The separation between building the structure of the \software{odML} document and the enrichment with metadata makes parts of the structural templates usable for other experiments if they contain similar hardware, software or preprocessing components. However, the code for enriching these template structures is highly specific to the non-standardized formats of the metadata source files in this experiments. Therefore the reusability of the presented workflows for other experiments is limited to parts of the structural template of the \software{odML} document and a few generic routines (\requirement{R7}).

The compilation of the \software{odML} document in the presented pipeline is a single Python script that relies on a number of additional Python modules for the aggregation process. No provenance is captured in the process and the final \software{odML} file does not contain any information about its generation process (\requirement{R8}). In particular, this means that for the \software{odML} file it is impossible to match the version of the \code{ReachGraspIO} or the \software{odMLGenerator} and the content can not be verified. Possible extension to the pipeline could be the usage of a provenance tracking tool like Sumatra\footnote{\url{https://pythonhosted.org/Sumatra/}} or explicit tracking of file and package versions used in the pipeline.

For accessing the data in combination with the collected metadata in the \software{odML} format multiple software requirements need to be installed in specific versions: \software{Neo} for providing the data structure, \software{odML} for metadata handling, the experiment specific \code{ReachGraspIO} for combining the two as well as the original data files with a specific version of the \software{odML} file. All of these have version interdependencies, which need to be considered when setting up an analysis based on the published data. In particular, version requirements of the analysis process may conflict with that of the code to access the original data files, e.g. by requiring different \software{Neo} versions. Therefore installation of an analysis pipeline based on the published dataset requires some effort and time and can be demanding for non-experts (\requirement{R9}). Also, this may lead to analysis relying on outdated package versions and not benefiting from bug fixes and upgrades, as dependencies are restricted by the the packages required for initial loading of the data.

In the presented workflow the consistency of data and metadata is not explicitly checked. Especially after the \software{odML} file generation, there is no mechanism to validate the metadata and data (\requirement{R10}). An indirect mechanism to ensure consistency of data and metadata files is to introduce provenance tracking (\requirement{8}) in combination with version control mechanisms (\requirement{R4}).

By using Python for the presented metadata pipeline in combination with the open-source software packages \software{odML}, \software{odMLtables} and \software{Neo} \citet{Brochier_2018} rely strongly on open-source software (\requirement{R11}). Some exceptions are preprocessing steps, which are required to generate the metadata source files, e.g. spike sorting using \software{Plexon} and a custom event detection implemented in \software{Matlab}. Also the recording setup is based on \software{Windows} and closed-source recording software by \code{Blackrock Microsystems}, but in principle alternative open-source projects electrophysiology recordings (open ephys\footnote{\url{http://www.open-ephys.org/}} and spike sorting (e.g. tridesclous\footnote{\url{https://github.com/tridesclous/tridesclous}} exist, but need to be evaluated in the context of this and future projects.\\

In summary, the presented pipeline constructs a metadata collection, which in adheres partially the FAIR principles, as it uses the standardized \software{odML} format and open source tools for metadata aggregation. However, the process of metadata aggregation presented here is complex and tedious making the implementation of the FAIR principles labour-intensive. Additionally, the recording data are stored in proprietary formats which inherently only contain minimal metadata and lack interoperability. In the following we will present two projects for facilitated metadata acquisition (\ref{sec:metadata}) and standardized data representation (\ref{sec:neo}).



